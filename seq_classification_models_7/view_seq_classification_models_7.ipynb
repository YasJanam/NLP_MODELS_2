{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKXmzlNBPQuo",
    "outputId": "75dfbac1-baca-4195-b232-a9468a24a8d9"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning  seqeval evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfgkWyGSPCpF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from evaluate import load as load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from google.colab import files\n",
    "import builtins\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0P-RcfrKPUbd"
   },
   "source": [
    "#### **Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "0cc430a1322247a1abf3095d593f8849",
      "623864491a6b43449eec123d988f8f24",
      "fa2818f557d34da08ce9a9fd90a5248a",
      "0da47867b6dc48a79ff85f044592ccd5",
      "1c96f28c002146d5909a78347f1862b8",
      "95fb16e91029463ab40fc8b506b118b9",
      "510089bf162e4aa19a35bf473ce98356",
      "bdb4d591cfc6494d8c3ad67210f3609f",
      "f6031eb2f8fe46a9b47d5048b4d11132",
      "9dbed3e2558e4098afd697340d10fb1e",
      "f0157f25f4e04f26983c836484543e29",
      "e29c23f754ea4064953f6b92d4df8d33",
      "a331859b267d473587c76362b9adf731",
      "7020d659ce30452f817eac263dcfe25e",
      "51e992adcfbd41bb8d605b5b185d764d",
      "9cc68f21fc714aaaa7e1c85b3204e274",
      "3a0c1cef9e59489287a37215fa76e5c3",
      "8a2ba999efad4951b535ae29a48a2298",
      "666746db6d86446eaa243314dd0263a3",
      "fdd440ef15eb4031bf18a139e3c91c9b",
      "d39eda7503694b9b9f42b4466c99436a",
      "62a42bca874a421fafce9b4417125553",
      "5600dc6ba5594d8cb9a4feb2a609f448",
      "a7c69e00a3bc483bbaecefb0c110b623",
      "9218f9f0ba2d4bfe8dc0d9123ef0594d",
      "43bf66b2eaf4497cb372425bae5497ea",
      "9f80526b917849f2aeeb21dc8516a493",
      "318219f45abe44a5974b473731e0ae93",
      "9178f2389b2846c795f5afcff96a205d",
      "9f0754bad3304265a6f7e80c635d07c5",
      "35dd36d0066e44ed98b275ae782f0a9f",
      "9f3ba7e90cfc4f73a6bd008df14894ec",
      "ddefd463e9ca4175953e2348139a90f3",
      "3ec293daf57d43529cc4ffbee377d2cb",
      "94eedc458a0944448466c2691c421e25",
      "e218329a2e944cd7b5e561b387222800",
      "20a061e44fce4826b4242da6eee518f4",
      "e6ad85670d8d40029a03ac584513a54a",
      "7fa98d5325874930871e358c92c730b3",
      "59d2e1fc0d7f4c858ee170be8b376df8",
      "fa093a65ee934b6fa47cdcd2a16f750b",
      "40a0f2f66cbe43418046fa80b4723136",
      "a2b78bd80d314592ba5f23b847128784",
      "2162035111104b4f9fd4bdf168a31fe4"
     ]
    },
    "id": "cU6GT93oPU3c",
    "outputId": "fd5210c7-e969-4c78-c6cd-550cc2970700"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc430a1322247a1abf3095d593f8849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29c23f754ea4064953f6b92d4df8d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5600dc6ba5594d8cb9a4feb2a609f448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec293daf57d43529cc4ffbee377d2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def upload_dataset_from_system():\n",
    "  uploaded = files.upload()\n",
    "  data = Dataset.from_pandas(pd.read_parquet(list(uploaded.keys())[0]))\n",
    "  return data\n",
    "\n",
    "# --- return dataset classes ---\n",
    "def dataset_classes(dataset):\n",
    "  return list(set([item['label'] for item in dataset]))\n",
    "\n",
    "# --- tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "\n",
    "# --- max , mean of dataset lengths ---\n",
    "def get_max_mean_length(dataset,text='text'):\n",
    "  lengths = [len(tokenizer(x)['input_ids']) for x in dataset[text]]\n",
    "  return {\"max\":builtins.max(lengths) , \"mean\":statistics.mean(lengths)}\n",
    "\n",
    "# --- percentile ---\n",
    "def get_percentile(dataset,per_list=[98,99,99.9],text='text'):\n",
    "  lengths = np.array([len(tokenizer(x)['input_ids']) for x in dataset[text]])\n",
    "  return np.percentile(lengths,per_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "Ie7BFs9_PaCp",
    "outputId": "b2e84eed-8c23-4055-b4e3-a7ea0f988989"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-eb88ece9-6e83-4a07-979d-8ae0084390fd\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-eb88ece9-6e83-4a07-979d-8ae0084390fd\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train-00000-of-00001.parquet to train-00000-of-00001.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-83445ded-1fac-47a4-897b-6337a2142192\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-83445ded-1fac-47a4-897b-6337a2142192\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving validation-00000-of-00001.parquet to validation-00000-of-00001.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ec903c75-92b7-49a5-ab6b-b3cd9a5127e5\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-ec903c75-92b7-49a5-ab6b-b3cd9a5127e5\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test-00000-of-00001.parquet to test-00000-of-00001.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- load dataset 20-classes ---\n",
    "train_data = upload_dataset_from_system()\n",
    "val_data = upload_dataset_from_system()\n",
    "test_data = upload_dataset_from_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRzhTCJeWhQ6",
    "outputId": "13edc805-c3bb-4e2d-bd13-49c4bcf0f8c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {'max': 75, 'mean': 21.237466666666666}\n",
      "val {'max': 57, 'mean': 19.7332}\n",
      "test {'max': 93, 'mean': 21.28922}\n",
      "train_percentile [34. 35. 37. 42.]\n",
      "val_percentile [33. 34. 36. 40.]\n",
      "test_percentile [34. 35. 37. 42.]\n"
     ]
    }
   ],
   "source": [
    "print(\"train\",get_max_mean_length(train_data))\n",
    "print(\"val\",get_max_mean_length(val_data))\n",
    "print(\"test\",get_max_mean_length(test_data))\n",
    "print(\"train_percentile\",get_percentile(train_data,per_list=[97,98,99,99.8]))\n",
    "print(\"val_percentile\",get_percentile(val_data,per_list=[97,98,99,99.8]))\n",
    "print(\"test_percentile\",get_percentile(test_data,per_list=[97,98,99,99.8]))   # max_length -> 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328,
     "referenced_widgets": [
      "714065805f4240d188d2526bd1d8e055",
      "4e6b827b2f89460c9f6cfc5fdf532eef",
      "c1f7e7d6727d48f7943de7ac320df45e",
      "589f47a23d48431081ebfc4342afc99b",
      "15597a7b957745c79570c8354961bc29",
      "fcd9b41d6e474d4093487123b7783d14",
      "3617adc1e09c4a78a8151486b4b6a434",
      "9504c22000d74a45ab19845a0048bb9f",
      "be948c25fde340b99839e496d3b5a0d5",
      "eec31fc18d1347ec8742210ed40c4366",
      "06b545ed9897479b849dac29c47a9ca9",
      "689121b5e48d4c298a02cb96c437489f",
      "8919e0ce32ef4a9aa42a29c9ed750f9e",
      "2bf1920d6916495ca9f1d6f22514a73a",
      "bb8829e708044783baf3d569d487d035",
      "992fea29f58b41aa8a8c0129405d02b5",
      "e1b2cb96305046bf9bebecea3df42e2d",
      "b7c85db0b7ba4ba1a42cedf3df6ba755",
      "2497adb650104cc18c62129f112db3d1",
      "d2af7f4cada64500a2f05a5663b188cd",
      "49ad0b0a8c8d4eeb8514b971e10b21a8",
      "9524324eee934f0a8a774ae373b5a6e9",
      "a97bde8dbb784c72b200e5ee329463b6",
      "9c44a46a4c3b454da8a8b036b914f9bf",
      "d7bb7b9a82034c22a952b758fd694af7",
      "bc6cbe01141e4e55bc392e09156d9432",
      "147b6439075042aabaf0daac186a834a",
      "c53369791b1246168d2aa541dd437472",
      "973e88e4160a46ddaa0fd53f34c63e51",
      "0b924711763e4b609b11c622fbf851ea",
      "b9511eadcf9c41b0bfc4207c439c20a4",
      "9ce2c31b63ca4904a4b0e11cba3e3c99",
      "29371cab974e42969fc2abdc4e78afaf",
      "2bcc4be4c3b1409d9f0ca041c2e408dc",
      "5d95df38f4ed49e4a7b0c25b108feef3",
      "69904f485af0476cb02500fb95d52854",
      "76c19ff199c9431eb260956e3101e73a",
      "c5a5bf3ee47a400dbd319f1c483bd9d6",
      "ce42261c45f145be9a9c7a9a48fd00cd",
      "a20499bb4d61468c8c10e66e3c0ebbc6",
      "618950ac3f33405aa9dc462da68d8a44",
      "b0bd198ea15f4f589b009c16c9b159dc",
      "0cd290a5a5b74050889da90f97da0506",
      "ccbe8163a2b34ac099f8b67068531c3c",
      "46828410e964492dbca3ad0bc3d10193",
      "6e2afff63d4140259bf818bfbf5737e5",
      "467aac3a93f9486d9491a50990b2d97a",
      "49604edf4f9c4952a1bf9907417caf53",
      "de082a538eff4f1f93e2982c2782658b",
      "8ae47148e65347c8b4a6f64275b7b2d9",
      "a7010eee130c45cd82ce490218ebbfd2",
      "de8aa021ac3a4c61980829c96ef7c74f",
      "d4347390ffbc46c69ee961ed89ceb174",
      "8ce253a6dc0345899feb69fb4ebc4ae5",
      "acf7d38d70854a37a512a5596871b323",
      "185b81690a5344e689c7381db3506e86",
      "bae643c9e4934adca3b9bba35dc0d7d6",
      "3ab80aa038ed4548bb3d1864e98d6b45",
      "58ca3aff8b7140648d2f6f269071419d",
      "471d477ec06340c48c7982e41372eb6b",
      "a272f94d5bfd40078e59c807e1f3f0da",
      "0a9a7eb537144493a29597a636e294aa",
      "e54915ff29b5488780aff5a84d6e25a9",
      "5b3653cda3ea49e089fe80c8e2cbfaae",
      "6eb327a1df914089b7e764952133a75e",
      "8ff6335e217d4038b035c47ad640f59e",
      "d55423424268444b8ca3467df6168d9d",
      "5acf47f4ab1a4eabb0421cbde316a1fd",
      "5b47323335394522a6fb75dda2279ead",
      "b87b605e862d44e9b9467055d2ca681e",
      "d6a53912234d4db19678ac6657c2f67c",
      "ee2bcd75e518437fb443ed2514eb81dd",
      "9cfa20e72e20436a9215ef104f8c4a76",
      "3e3616699c27493297a398e168841607",
      "985819a71d8f4001936fa100e28cc821",
      "f462fac928584accb7bd2eac1b740619",
      "031ca04ed037434fb7c6d23e17c93f32"
     ]
    },
    "id": "jZB15Vh7PfC_",
    "outputId": "085a6c18-7c31-4065-923d-86b38705ff8d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714065805f4240d188d2526bd1d8e055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/421 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689121b5e48d4c298a02cb96c437489f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97bde8dbb784c72b200e5ee329463b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcc4be4c3b1409d9f0ca041c2e408dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46828410e964492dbca3ad0bc3d10193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8544 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185b81690a5344e689c7381db3506e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55423424268444b8ca3467df6168d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films',\n",
       " 'label': 4,\n",
       " 'label_text': 'very positive'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- load sst5 ---\n",
    "sst = load_dataset(\"SetFit/sst5\")\n",
    "sst['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GneNS1t-SYEP",
    "outputId": "c0d6abdd-e289-4f3f-b907-fe8f69be1873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {'max': 80, 'mean': 25.039911048689138}\n",
      "val {'max': 60, 'mean': 25.236148955495004}\n",
      "test {'max': 70, 'mean': 25.000452488687785}\n",
      "train_percentile [49. 52. 55. 61.]\n",
      "val_percentile [48.  50.  53.  56.6]\n",
      "test_percentile [48.   50.   53.91 59.  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"train\",get_max_mean_length(sst['train']))\n",
    "print(\"val\",get_max_mean_length(sst['validation']))\n",
    "print(\"test\",get_max_mean_length(sst['test']))\n",
    "print(\"train_percentile\",get_percentile(sst['train'],per_list=[97,98,99,99.8]))\n",
    "print(\"val_percentile\",get_percentile(sst['validation'],per_list=[97,98,99,99.8]))\n",
    "print(\"test_percentile\",get_percentile(sst['test'],per_list=[97,98,99,99.8]))      # max_length -> 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484,
     "referenced_widgets": [
      "920bfef6a5e34a039abee02ce6bc482c",
      "fc47c2777b914c61acca39c079ec71af",
      "ec20147aee464f8f962a4c367514a813",
      "ad4191973b7b4cea875bf3866caa6ebe",
      "e85a36b6232949d4b0ec739b5159e09f",
      "d13d1e7b7bc04e01af1efc2ac0644671",
      "0153be34a0694c51a8ac54b2486ef8d0",
      "a04cc6fcf1fe48d2981bbaba81801bc4",
      "1a17d06bee2d457a942cd26b7dbee403",
      "5951126b34604226aaa08d481b0495c1",
      "2166432369434be8b2d0627475ac3acb",
      "943ca34e3c8e4aafba9cd7a0af83f94a",
      "4017657754ca429e97f1bcf8daf3594a",
      "5f75d79237d9415cba6aa7250844957b",
      "204ac06b8dec4888bcc0fb1618c2111a",
      "2cd8af2135db47f2a6a69050f505fce1",
      "3511fce0e1f447c0a3e3186dde4469d2",
      "99e4d53349d54e259a2ddf76ff69ed98",
      "5194458a24b040f99173ce9682ca0e43",
      "fa84def7e36d4822903a962b63ea67f8",
      "2a43e82988f141049b5aa2ec88916f88",
      "6ede4af91101461482a3298896f9b8ca",
      "5cc07ab730ea431185c0d4e482d33375",
      "142ebba665044a558a300f1bc5147ba9",
      "ce02730d98d84ea2bb113fb09ac3b2b9",
      "4176fe880ef543dd982d91a93e92959e",
      "8f6c71efad9240aea52c70b199f8731f",
      "c22244b54e154ebe9e6436025533d51c",
      "872c93e7cca847c9a38281d0bf51fcd3",
      "e2df361fb1be420e878be0ef5384ed66",
      "7f76169b388e42f7a5bddfb5f32bfbc0",
      "456475be98904bf3bf79254f4fafad2e",
      "60702a50eacd41b3923652106605eeae",
      "9c845dbc0d3b473181c1310249e04f77",
      "4e0a641c4a544aa284697a4b62ba37d8",
      "bcccc44177ef47ae89cac0357e8f41fd",
      "e19c1417453b49bcbc83f835fe3d5224",
      "5b45726b0b57417386546525d01e0300",
      "25419a651ce549e39ca19529571e40fd",
      "d3aa628fc6a542239f48c7136f12accd",
      "bf1b351990154054b2bf42e577b484fa",
      "ce52dfbf87d240c89663231f60e67498",
      "5425aaa3fbd84929b1a98dc580420324",
      "0746b454c52b431b8262bdeb00ac5383",
      "5e718cfd11a84b2b95571db90572ebe1",
      "121ad1938d514d44bf62f35b2838cb49",
      "2f94f3c0571248ae8d22d58edf173a39",
      "a42c05a70dd141a98b15d57e9e4cf42a",
      "b1f3d280786c4f6f8ad02eb5833f187d",
      "cdde4c2a6cf24e59adadac5a7e3be780",
      "9f634380a4eb4c9bafd1d964c601c9aa",
      "488bc7b72e2e472f8ef958fe76703a5a",
      "30282ce4e3ac4f18a4f7d3ae9f20c69d",
      "a1dbe0d501f74f6a9878d01507a29bf3",
      "cfdedb17282d44fc891babf048f37b60",
      "0891bd0323514ac6b4792ba163631f97",
      "6f62c4b65bed4c39b2e91b45c5a397e9",
      "332805a988f04c16850c225253b56429",
      "3b1f4d8a019048fd9a51c05d1b838f3a",
      "b619bbada22349ceaa67cc768e7f0052",
      "bddfa46e9afd414590bde32fffd328c1",
      "105800e2bef04b75bd8e56ab5ec1e3b8",
      "b83fe0835b6d49dcb1456f0809f9c0a6",
      "f959858af5004e918a244f31fe042c16",
      "c959e56765464b79aaed233c9777fae3",
      "b01e763a24cf477dbbb69259a9e9ff7c",
      "8fceba036a5743b9aff4ae118ba2df61",
      "5dec2665cf4c48618bd9e3b85d7f4132",
      "bbadc519f9954550b0c13643eee21521",
      "7b8b22ecbd6f4f479d7cc9da76d67668",
      "fca05b00ee13452dbd7c32ef85b7511d",
      "3e2de89c2a334e9aa299c988deb93a8b",
      "b65dc5ddb0f7465287e0d39cbbc45a30",
      "9f9d9ab5aa374f78866400dfa123cb84",
      "b962adb2e08d47d98fc0070c24e22833",
      "46cd9248d9454f208ff24f8347c52a98",
      "6bb88cf035624736b0b0e7608699a7ab"
     ]
    },
    "collapsed": true,
    "id": "ycm6lOkzPiNS",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ad9d314c-a3b0-435c-80c4-93358222eb81"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920bfef6a5e34a039abee02ce6bc482c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943ca34e3c8e4aafba9cd7a0af83f94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc07ab730ea431185c0d4e482d33375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c845dbc0d3b473181c1310249e04f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e718cfd11a84b2b95571db90572ebe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0891bd0323514ac6b4792ba163631f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fceba036a5743b9aff4ae118ba2df61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- load imdb ---\n",
    "imdb = load_dataset(\"imdb\")\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGBTSuFGSycA",
    "outputId": "82b8dff1-b589-432c-f6ef-d96228d15fa2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {'max': 3127, 'mean': 313.87132}\n",
      "test {'max': 3157, 'mean': 306.771}\n",
      "train_percentile [1055.    1206.    1530.014]\n",
      "test_percentile [1032.    1192.01  1407.007]\n"
     ]
    }
   ],
   "source": [
    "print(\"train\",get_max_mean_length(imdb['train']))\n",
    "print(\"test\",get_max_mean_length(imdb['test']))\n",
    "print(\"train_percentile\",get_percentile(imdb['train']))\n",
    "print(\"test_percentile\",get_percentile(imdb['test'])) # max_length -> 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDlvwT8C30a3"
   },
   "source": [
    "#### **preprocess & Dataset-utilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwtnfeH7ZiTb"
   },
   "source": [
    "**preprocess_data :**\n",
    "\n",
    "رو ورودی دادم. اما چرا ؟ max_length در این متد\n",
    "\n",
    "sst چون بعضی دیتاست ها تسکت هاشون کوتاهه. مثل  \n",
    "\n",
    "- sst_max_length : 80\n",
    "- sst_mean_length : 25\n",
    "\n",
    "imdb و بعضی دیتاست ها تکست هاشون بلنده. مثل\n",
    "\n",
    "- imdb_max_length : 3127\n",
    "- imdb_mean_length : 313\n",
    "\n",
    "دیتاست 20 کلاسه :    \n",
    "\n",
    "- 20_cls_data_max_length : 75   \n",
    "- 20_cls_data_mean_length : 21\n",
    "\n",
    "متناسب با دیتاست انتخاب بشه max_length خب پس بهتره که\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXJLZBi0LoDO"
   },
   "outputs": [],
   "source": [
    "\n",
    "def preproces_data(example,max_len,text ='text',label = 'label'):\n",
    "  tokenized_item = tokenizer(example[text],truncation=True,max_length=max_len,padding=\"max_length\")\n",
    "  inp_ids = tokenized_item['input_ids']\n",
    "  attn_msk = tokenized_item['attention_mask']\n",
    "  label = example[label]\n",
    "\n",
    "  return {\n",
    "         \"input_ids\": inp_ids, # Convert list to tensor\n",
    "          \"attention_mask\": attn_msk, # Convert list to tensor\n",
    "          \"labels\": label # Return the original label index\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182,
     "referenced_widgets": [
      "9b802f5875cf452783f53fea9a3b171c",
      "9198c3cf7b0846c4aa8d36b8c6c2a8e6",
      "e99ec20cc1b44e1c8d96977cc00c17cd",
      "f7b6491d57c648bb810647a95bf68c16",
      "cc0510d0acb643cab9c9d042eba45e4a",
      "5407ec05d2794a0883946e833cdb400f",
      "732793b56b1947b795a7db39da7d7dcd",
      "358f57813116419b861a6475ba127dc7",
      "0e4a74ea68df414c98c6c120c7c9aaa5",
      "fd19aa2ef6c84048aa4fa38d63431132",
      "ff893dcc56ed4483bdc7e2157fc4c511",
      "ef65f8abb2ce405888d3a8bf3a370ce9",
      "2784d8a26b1a4179901c2ad3d3cbef78",
      "559e6157ff914c87ac0dbaf4a3e90264",
      "faa0978cca82417da8effdf160c1440e",
      "f30565071a48426bb65fa073db09db0f",
      "7c7d53211a2347db8970376af3d54e29",
      "e3e2da12de2041e184fe7aea07a1a4ca",
      "430118c7bb5a4311a21efa40964b7aea",
      "c4451c554ca649568ab460305962e073",
      "d07d8a988add41c6bca475167fb932c4",
      "56e9d75d4b3f424f852a39d378f00560",
      "463ce6156e3449a695301148384f0877",
      "2c1c51d175134d20b0f49178e12fcedb",
      "f0fc8542ab164843bb7b822f01294ef7",
      "a313ea4532db43949c87c05163bf5109",
      "3aadff3e625740c687531491bab56c9d",
      "f844a1e8a51f43f7ba89179566c53f9b",
      "05331a0799df47758226cb397d9f67a7",
      "d5cbcc914a674231b9d28f24718378ee",
      "9a030ec4bff8485e9b7a0474fa36c489",
      "8171385929674769a7cf0804641f5b05",
      "633090da590248ad98989b5299957b6a"
     ]
    },
    "id": "373VZgLSnVuk",
    "outputId": "4e813a50-e164-41f2-b2ad-c79666bf50d3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b802f5875cf452783f53fea9a3b171c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef65f8abb2ce405888d3a8bf3a370ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463ce6156e3449a695301148384f0877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 45000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 20 classes dataset ---\n",
    "train_dataset = train_data.map(preproces_data, fn_kwargs={'max_len': 40}, remove_columns=['text','label'])\n",
    "val_dataset = val_data.map(preproces_data, fn_kwargs={'max_len': 40}, remove_columns=['text','label'])\n",
    "test_dataset = test_data.map(preproces_data, fn_kwargs={'max_len': 40}, remove_columns=['text','label'])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182,
     "referenced_widgets": [
      "e26ceb71323748259443044655a015ad",
      "c14a19194da54fe8aa6bc99e89f1d9fb",
      "2ac4defa129747a7825d4be5b07d867f",
      "a6aeb89f311a44c2bab24c4041b564d5",
      "b349d931da3d45bd846c53a629a5a173",
      "52aee067191b4ca8a8ce9b8b55d6609f",
      "ccb36f9f75f74164a8d61249e94f6ada",
      "957ab294960646f29b6ce85af0ec863f",
      "33e487b7516348e699c6a2a4117962d4",
      "2b5087678d264211975fc5ad6a5fe884",
      "2570d6117f924a01ade61970bb795f49",
      "b5f120823d61467289e3959cc4f265a2",
      "5d95cc848c5c4683bef3075b9ff7dc48",
      "f9c2262f8548460dbe8a1904a0873ca2",
      "93f380f2e1d9447e9ec579090feb992b",
      "d39d08fef9e0468b88de5d4a2df9896f",
      "050f20a422394c48bcfe0825a60c8cc2",
      "0303f33a5a064dadb3679314c3b0893b",
      "34cc9fd1158f4736b21e75a95d069241",
      "a77e76af5ac64eafbd9b5fd254f884b0",
      "91b5cdb18ee94c259d2a4ceeecf4cd97",
      "dd8785bca9924767af8a5fbf99e2aecf",
      "2dad91d072c041caae61aa6bc964970e",
      "b704056e2bc04509a7ba8a2b412a3da6",
      "5dd295d662fa4a4cb468a3c4753ab68d",
      "c6acb119e07d40539a1287c18d8d93f8",
      "4cde0b6f75d546fab1797a8ad61b2385",
      "3ffe455f8b4247199a203212e09d4fb9",
      "284f6bcda3354ec4b1b96acd4865d07d",
      "5710b077c3274a898eebe4b8cab84e0b",
      "0376b84b83e64cb9b334b6a5cc6c8582",
      "864353e863664feb906eeca27892b6e8",
      "c2184980a946412eb3bd7e1cb482c9b1"
     ]
    },
    "id": "sw4-lBOhN09d",
    "outputId": "589c8d67-338f-4721-efa5-df2021d1784e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26ceb71323748259443044655a015ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8544 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f120823d61467289e3959cc4f265a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dad91d072c041caae61aa6bc964970e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 8544\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- sst5 ---\n",
    "sst_train = sst['train'].map(preproces_data,fn_kwargs={'max_len': 60},remove_columns=['text','label','label_text'])\n",
    "sst_val = sst['validation'].map(preproces_data,fn_kwargs={'max_len': 60},remove_columns=['text','label','label_text'])\n",
    "sst_test = sst['test'].map(preproces_data,fn_kwargs={'max_len': 60},remove_columns=['text','label','label_text'])\n",
    "sst_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150,
     "referenced_widgets": [
      "b18370b8b70e40e89516a4169d18c238",
      "5830ee669cea4c7e865c4d15304a3c64",
      "6b28adf6e1d14b80a41b5c780443b056",
      "312ef05249e94741b1268f4f2b866890",
      "98d56c887c30406abc9fe84419600788",
      "3c60d25e366246a897c13b9d07295caf",
      "7d13408446e445c29bda3af3a761117f",
      "6f6ba07eded94070849f02dd42164b4b",
      "3b51f7bedf684ccf8a5a6dc3c0743a35",
      "b904115692a24efaa0adb02449d589dc",
      "7ff84fdaeff2457d869f36ca26a71c3b",
      "a3664447441343599c29bb14bf9a4e27",
      "f6fd42c273ad42f99a2b5667d8c03743",
      "eac915f903ac40e7954d38c5d456b17a",
      "cb3fde19dd1747649e2085acb36cb2ca",
      "78f7d2d5dc594598bcd065fc8ae6cbf4",
      "c7755e4a98e046ddab7b2152145acdec",
      "f7705706329e4bbaaeeb9c4aeb8c1065",
      "45dc6265381e459aaa3e16bb811683d9",
      "d30132aa085c4831b2f2edc4d283aeb9",
      "5f3fad760801452f93eb88bd5d68e7cd",
      "70ca4617ad1448d3a0d37f7fde644de8"
     ]
    },
    "id": "BmPvp_kznQdt",
    "outputId": "3ee88190-7a49-4a4b-cd74-a23d9a8fe44a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18370b8b70e40e89516a4169d18c238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3664447441343599c29bb14bf9a4e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train = imdb['train'].map(preproces_data,fn_kwargs={'max_len': 1200},remove_columns=['text','label'])\n",
    "imdb_test = imdb['test'].map(preproces_data,fn_kwargs={'max_len': 1200},remove_columns=['text','label'])\n",
    "imdb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AW61SrZLks7i"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [\n",
    "        torch.tensor(item['input_ids'], dtype=torch.long)\n",
    "        if not isinstance(item['input_ids'], torch.Tensor) else item['input_ids'].long()\n",
    "        for item in batch\n",
    "    ]\n",
    "    attention_mask = [\n",
    "        torch.tensor(item['attention_mask'], dtype=torch.long)\n",
    "        if not isinstance(item['attention_mask'], torch.Tensor) else item['attention_mask'].long()\n",
    "        for item in batch\n",
    "    ]\n",
    "\n",
    "    labels = torch.stack([\n",
    "        torch.tensor(item['labels'], dtype=torch.long) # Changed to torch.long\n",
    "        if not isinstance(item['labels'], torch.Tensor) else item['labels'].long()\n",
    "        for item in batch\n",
    "    ])\n",
    "\n",
    "\n",
    "    input_ids_padded = pad_sequence(\n",
    "        input_ids, batch_first=True, padding_value=tokenizer.pad_token_id\n",
    "    )\n",
    "    attention_mask_padded = pad_sequence(\n",
    "        attention_mask, batch_first=True, padding_value=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_padded,        # (batch_size, seq_len)\n",
    "        \"attention_mask\": attention_mask_padded,  # (batch_size, seq_len)\n",
    "        \"labels\": labels                      # (batch_size, num_classes)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9yNhxHHOIxe"
   },
   "source": [
    "##### **LitModule**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZRwL32pELzn"
   },
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau # Import ReduceLROnPlateau\n",
    "\n",
    "class LitModule(pl.LightningModule):\n",
    "  def __init__(self,model,batch_size=64,lr=1e-3,train_dataset=train_dataset,val_dataset=val_dataset,test_dataset=test_dataset):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "    self.batch_size = batch_size\n",
    "    self.lr = lr\n",
    "    self.train_dataset = train_dataset\n",
    "    self.validation_dataset = val_dataset\n",
    "    self.test_dataset = test_dataset\n",
    "\n",
    "    self.loss_fn =  nn.CrossEntropyLoss()\n",
    "\n",
    "    self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.model.classifier.out_features)\n",
    "    self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.model.classifier.out_features)\n",
    "    self.train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.model.classifier.out_features)\n",
    "    self.val_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.model.classifier.out_features)\n",
    "    self.test_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.model.classifier.out_features)\n",
    "    self.test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.model.classifier.out_features)\n",
    "\n",
    "    # F1 per-class\n",
    "    self.test_f1_per_class = torchmetrics.F1Score(\n",
    "        task=\"multiclass\",\n",
    "        num_classes=self.model.classifier.out_features,\n",
    "        average=None\n",
    "    )\n",
    "\n",
    "  def forward(self,input_ids):\n",
    "    return self.model(input_ids)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True,collate_fn=collate_fn) #sampler=self.sampler\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(self.validation_dataset,batch_size=self.batch_size, collate_fn=collate_fn)\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(self.test_dataset,batch_size=self.batch_size, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "  def training_step(self,batch,batch_idx):\n",
    "     input_ids = batch['input_ids']\n",
    "     labels = batch['labels'].long()\n",
    "\n",
    "     logits = self.model(input_ids)\n",
    "     loss = self.loss_fn(logits, labels)#self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "     self.log(\"train_loss\",loss)\n",
    "\n",
    "     preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "     self.log('train_acc', self.train_accuracy(preds, labels), on_step=False, on_epoch=True, prog_bar=True)\n",
    "     self.log('train_f1', self.train_f1(preds, labels), on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\n",
    "     return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    input_ids = batch['input_ids']\n",
    "    labels = batch['labels'].long()  # shape: [batch_size]\n",
    "\n",
    "    logits = self.model(input_ids)              # shape: [batch_size, num_classes]\n",
    "    loss = self.loss_fn(logits, labels)\n",
    "    self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=-1)        # shape: [batch_size]\n",
    "    self.val_accuracy.update(preds, labels)\n",
    "    self.val_f1.update(preds, labels)\n",
    "\n",
    "    self.log('val_acc', self.val_accuracy, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input_ids = batch['input_ids']\n",
    "    labels = batch['labels'].long()\n",
    "\n",
    "    logits = self.model(input_ids)\n",
    "    loss = self.loss_fn(logits, labels)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # فقط update کنیم\n",
    "    self.test_accuracy.update(preds, labels)\n",
    "    self.test_f1.update(preds, labels)\n",
    "    self.test_f1_per_class.update(preds, labels)\n",
    "\n",
    "    self.log(\"-- test_loss --\", loss, prog_bar=True)\n",
    "\n",
    "  def on_test_epoch_end(self):\n",
    "    acc = self.test_accuracy.compute()\n",
    "    f1_macro = self.test_f1.compute()\n",
    "    f1_per_class = self.test_f1_per_class.compute()\n",
    "\n",
    "    # لاگ نهایی\n",
    "    self.log(\"-- test_acc --\", acc)\n",
    "    self.log(\"-- test_f1 --\", f1_macro)\n",
    "    for i, score in enumerate(f1_per_class):\n",
    "        self.log(f\"test_f1_class_{i}\", score)\n",
    "\n",
    "    # ریست کردن\n",
    "    self.test_accuracy.reset()\n",
    "    self.test_f1.reset()\n",
    "    self.test_f1_per_class.reset()\n",
    "\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "     scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)  # ✅ روی val_loss باید min باشه\n",
    "     return {\"optimizer\": optimizer,\"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O225dzxe0hvo"
   },
   "source": [
    "#### **weight-initialize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OIM8xam0mQP"
   },
   "outputs": [],
   "source": [
    "class InitWeight:\n",
    "    def __call__(self, m):\n",
    "        if isinstance(m, nn.LSTM):\n",
    "            for name, param in m.named_parameters():\n",
    "                with torch.no_grad():\n",
    "                    if \"weight_ih\" in name:\n",
    "                        nn.init.xavier_uniform_(param)\n",
    "                    elif \"weight_hh\" in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif \"bias\" in name:\n",
    "                        param.fill_(0)\n",
    "\n",
    "        elif isinstance(m, nn.Conv1d):\n",
    "            with torch.no_grad():\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            with torch.no_grad():\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OJXp5whREd2"
   },
   "source": [
    "#### **Attentions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfvfYWrLRITz"
   },
   "outputs": [],
   "source": [
    "class gru_Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.key = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.value = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.query = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.attn_drop = nn.Dropout(0.2)\n",
    "        self.resid_drop = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        # output, h_n = gru(x)\n",
    "        _, k = self.key(x)   # h_n\n",
    "        _, q = self.query(x)  # h_n\n",
    "        _, v = self.value(x)  # h_n\n",
    "\n",
    "        k = k.squeeze(0)\n",
    "        q = q.squeeze(0)\n",
    "        v = v.squeeze(0)\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) / math.sqrt(C)\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_drop(att)\n",
    "\n",
    "        y = att @ v\n",
    "        y = self.resid_drop(y)\n",
    "        y = y.unsqueeze(1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SfLsiyYRZuP"
   },
   "outputs": [],
   "source": [
    "class conv_Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Conv1d expects input (batch_size, channels, sequence_length)\n",
    "        self.key = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3,padding='same')\n",
    "        self.value = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3,padding='same')\n",
    "        self.query = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3,padding='same')\n",
    "        self.attn_drop = nn.Dropout(0.15)\n",
    "        self.resid_drop = nn.Dropout(0.15)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        # Permute dimensions for Conv1d: (B, T, C) -> (B, C, T)\n",
    "        x_permuted = x.permute(0, 2, 1)\n",
    "\n",
    "        k = self.key(x_permuted)\n",
    "        q = self.query(x_permuted)\n",
    "        v = self.value(x_permuted)\n",
    "\n",
    "        # Permute back to (B, T, C) for attention calculation\n",
    "        k = k.permute(0, 2, 1)\n",
    "        q = q.permute(0, 2, 1)\n",
    "        v = v.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) / math.sqrt(C)\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_drop(att)\n",
    "\n",
    "        y = att @ v\n",
    "        y = self.resid_drop(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jkD75cYZEiL"
   },
   "outputs": [],
   "source": [
    "class gru_Attention_2(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.key = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.value = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.query = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.attn_drop = nn.Dropout(0.2)\n",
    "        self.resid_drop = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        # output, h_n = gru(x)\n",
    "        k, _ = self.key(x)   # output\n",
    "        q, _ = self.query(x)  # output\n",
    "        v, _ = self.value(x)  # output\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) / math.sqrt(C)\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_drop(att)\n",
    "\n",
    "        y = att @ v\n",
    "        y = self.resid_drop(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cePDmegtZb_3"
   },
   "outputs": [],
   "source": [
    "class _MultiheadAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "              embed_dim=hidden_dim,\n",
    "              num_heads=num_heads,\n",
    "              batch_first=True\n",
    "           )\n",
    "    def forward(self, x):\n",
    "        return self.attn(x,x,x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SI9oOrZqRuWP"
   },
   "source": [
    "#### **FFN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYPQcw2cRxLI"
   },
   "outputs": [],
   "source": [
    "class conv_lstm_ffn(nn.Module):\n",
    "  def __init__(self,hidden_dim=128,ff_dim=128):\n",
    "    super().__init__()\n",
    "    self.fc = nn.Linear(hidden_dim,ff_dim)\n",
    "    self.conv1 = nn.Conv1d(ff_dim, ff_dim, kernel_size=3, padding=\"same\")\n",
    "    self.conv2 = nn.Conv1d(ff_dim, ff_dim, kernel_size=5, padding=\"same\")\n",
    "    self.lstm = nn.LSTM(ff_dim*2, hidden_dim, batch_first=True, bidirectional=False)\n",
    "    self.apply(InitWeight())\n",
    "\n",
    "  def forward(self,x):\n",
    "      x = self.fc(x)\n",
    "      y1 = self.conv1(x.permute(0, 2, 1)).permute(0, 2, 1)  # (B, 1, ff_dim)\n",
    "      y2 = self.conv2(x.permute(0, 2, 1)).permute(0, 2, 1)  # (B, 1, ff_dim)\n",
    "      y = torch.cat([y1, y2], dim=-1)        # (B, 1, ff_dim*2)\n",
    "      y = F.relu(y)\n",
    "      y, _ = self.lstm(y)                   # (B, 1, hidden_dim)\n",
    "      return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXVg2vfoT8dX"
   },
   "outputs": [],
   "source": [
    "class conv_lin_ffn(nn.Module):\n",
    "  def __init__(self,hidden_dim=128,ff_dim=128):\n",
    "    super().__init__()\n",
    "    self.fc = nn.Linear(hidden_dim,ff_dim)\n",
    "    self.conv1 = nn.Conv1d(ff_dim, ff_dim, kernel_size=3, padding=\"same\")\n",
    "    self.conv2 = nn.Conv1d(ff_dim, ff_dim, kernel_size=5, padding=\"same\")\n",
    "    self.proj = nn.Linear(ff_dim*2,hidden_dim)\n",
    "    self.apply(InitWeight())\n",
    "\n",
    "  def forward(self,x):\n",
    "      x = self.fc(x)\n",
    "      y1 = self.conv1(x.permute(0, 2, 1)).permute(0, 2, 1)  # (B, 1, ff_dim)\n",
    "      y2 = self.conv2(x.permute(0, 2, 1)).permute(0, 2, 1)  # (B, 1, ff_dim)\n",
    "      y = torch.cat([y1, y2], dim=-1)        # (B, 1, ff_dim*2)\n",
    "      y = F.relu(y)\n",
    "      y = self.proj(y)                       # (B, 1, hidden_dim)\n",
    "      return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sP5lbkmLYu9Z"
   },
   "outputs": [],
   "source": [
    "class lin_relu_ffn(nn.Module):\n",
    "  def __init__(self,hidden_dim=128,ff_dim=128):\n",
    "    super().__init__()\n",
    "    self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, hidden_dim)\n",
    "        )\n",
    "    self.apply(InitWeight())\n",
    "\n",
    "  def forward(self,x):\n",
    "    return self.ffn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6ia8b_WwfFo"
   },
   "outputs": [],
   "source": [
    "class lin_gelu_ffn(nn.Module):\n",
    "  def __init__(self,hidden_dim=128,ff_dim=128):\n",
    "    super().__init__()\n",
    "    self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, ff_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(ff_dim, hidden_dim)\n",
    "        )\n",
    "    self.apply(InitWeight())\n",
    "\n",
    "  def forward(self,x):\n",
    "    return self.ffn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8xBzMdbUumU"
   },
   "source": [
    "#### **CustomTransformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTmIbHgKU1cG"
   },
   "outputs": [],
   "source": [
    "class CustomTransformer(nn.Module):\n",
    "  def __init__(self, hidden_dim=128, attn=None,FFN=None,num_heads=4, ff_dim=256, dropout=0.1):\n",
    "      super().__init__()\n",
    "\n",
    "      # Attention\n",
    "      self.attn=attn if attn is not None else _MultiheadAttention(hidden_dim,num_heads)\n",
    "      # Feed Forward\n",
    "      self.ffn=FFN if FFN is not None else lin_relu_ffn(hidden_dim,ff_dim)\n",
    "\n",
    "      self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "      self.ln2 = nn.LayerNorm(hidden_dim)\n",
    "      self.drop1 = nn.Dropout(dropout)\n",
    "      self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x, mask=None):\n",
    "        # Self-Attention + Residual\n",
    "        attn_out = self.attn(x)\n",
    "        x = self.ln1(x + self.drop1(attn_out))\n",
    "\n",
    "        # FeedForward + Residual\n",
    "        ff_out = self.ffn(x)\n",
    "        x = self.ln2(x + self.drop2(ff_out))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccxONoBok4w3"
   },
   "source": [
    "#### **Creat_Module_List**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeBp8Qyuk733"
   },
   "outputs": [],
   "source": [
    "class Create_Module_list(nn.Module):\n",
    "  def __init__(self,hidden_dim=128,ff_dim=128,attn_ffn_tuples=None,num_heads=4,drop=0.1):\n",
    "    super().__init__()\n",
    "    self.drop=0.1\n",
    "    self.num_heads = num_heads\n",
    "    self.tuples = attn_ffn_tuples\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.ff_dim = ff_dim\n",
    "\n",
    "\n",
    "  def forward(self):\n",
    "    module_list = [CustomTransformer(hidden_dim=self.hidden_dim,\n",
    "                                           attn = item[0](hidden_dim=self.hidden_dim) if item[0] is not None else None,\n",
    "                                           FFN = item[1](hidden_dim=self.hidden_dim,ff_dim=self.ff_dim) if item[1] is not None else None,\n",
    "                                           ff_dim=self.ff_dim,\n",
    "                                           num_heads=self.num_heads,\n",
    "                                           dropout=self.drop) for item in self.tuples]\n",
    "\n",
    "    return module_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHEaCi2Paix2"
   },
   "source": [
    "#### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdBYTEKKamce"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self,vocab_size=VOCAB_SIZE,max_leng=256,hidden_dim=128,vocab=None,module_list=None,num_labels=20,num_repeats=4):\n",
    "    super().__init__()\n",
    "    self.word_embed = nn.Embedding(vocab_size, hidden_dim)\n",
    "    self.pos_embed = nn.Embedding(max_leng, hidden_dim)\n",
    "\n",
    "    self.layers = nn.ModuleList([item for item in module_list for _ in range(num_repeats)])\n",
    "    self.classifier = nn.Linear(hidden_dim, num_labels)\n",
    "    self.apply(self._init_weights)\n",
    "\n",
    "  def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.Embedding):\n",
    "            nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "  def forward(self, input_ids):\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "\n",
    "        # word + positional embedding\n",
    "        x = self.word_embed(input_ids) + self.pos_embed(positions)\n",
    "\n",
    "        # Transformer layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Sequence pooling (mean pooling)\n",
    "        x = x.mean(dim=1)  # (B, H)\n",
    "\n",
    "        # Classification head\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUpss0lfeWFe"
   },
   "source": [
    "#### **Train-Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daXR_amnebjE"
   },
   "outputs": [],
   "source": [
    "def train_model(attn_ffn_tuples=None,\n",
    "                num_labels=20,\n",
    "                hidden_dim=32,\n",
    "                max_leng=256,\n",
    "                ffn_dim=64,\n",
    "                num_heads=4,\n",
    "                dropout=0.1,\n",
    "                lr = 1e-3,\n",
    "                batch_size=32,\n",
    "                num_repeat_modules=3,\n",
    "                vocab=None,\n",
    "                train_data=None,\n",
    "                val_data=None,\n",
    "                test_data=None,\n",
    "                early_stop=False,\n",
    "                patience=7,\n",
    "                max_epochs=5,\n",
    "                gradient_clip_val=5.0\n",
    "                ):\n",
    "\n",
    "  module_list_creator = Create_Module_list(hidden_dim=hidden_dim,\n",
    "                                           ff_dim=ffn_dim,\n",
    "                                           attn_ffn_tuples=attn_ffn_tuples,\n",
    "                                           num_heads=num_heads,\n",
    "                                           drop=dropout\n",
    "                                           )\n",
    "  module_list = module_list_creator()\n",
    "\n",
    "  model = Model(hidden_dim = hidden_dim,\n",
    "                max_leng = max_leng,\n",
    "                num_labels=num_labels,\n",
    "                module_list=module_list,\n",
    "                num_repeats=num_repeat_modules,\n",
    "                vocab=vocab\n",
    "                )\n",
    "\n",
    "  lit_module = LitModule(model,\n",
    "                         batch_size=batch_size,\n",
    "                         lr=lr,\n",
    "                         train_dataset=train_data,\n",
    "                         val_dataset=val_data,\n",
    "                         test_dataset=test_data\n",
    "                         )\n",
    "\n",
    "  early_stop_callback = EarlyStopping(monitor='val_f1',min_delta=1e-4,patience=patience,verbose=True,mode='max')\n",
    "\n",
    "  callbacks=[]\n",
    "  if early_stop:\n",
    "    callbacks.append(early_stop_callback)\n",
    "\n",
    "  trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=device,\n",
    "    logger=False,\n",
    "    callbacks=callbacks,\n",
    "    gradient_clip_val=gradient_clip_val\n",
    "  )\n",
    "\n",
    "  trainer.fit(lit_module)\n",
    "  trainer.test(lit_module)\n",
    "\n",
    "  return model, lit_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7K6YKPTuNTS"
   },
   "source": [
    "#### **Labs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718,
     "referenced_widgets": [
      "6cfb7ee0f0ff4a228f4e8b92dbe5eecf",
      "54843c4c97ae45eba10a1353d0bd215b",
      "774d8421a52c4ed5baa69b9ce8c3d179",
      "04813d03da904dc3813183e3f2dc1a79",
      "858ee7cebb184cd0b6bbdc5115c51f52",
      "9cfa6112fd3e4080880bd4eddcd58bf1",
      "106585018e9c430b98797cfee48bd7f0",
      "caf031738a1c4d94a0a1eda498283c68",
      "6677e77f6ba0448aa464318c230707e5",
      "68a9d58218474b3ba5057ddd72fe72e6",
      "fbb29bc4bd8949d092feb563489fc87d",
      "b5b48e1969d6458092fcba8495ff0a2d",
      "ec5825adf7ca4cc096086930fd020b6f",
      "3dcd6a284b4d4c9789ed6eaf0cb1c1f6",
      "611d81459b5b40adb77cea93342cd951",
      "17668a32f8104fe69351b94e09b2b45b",
      "19498318d25146aa92abfec48bb5d154",
      "492842bed3a0434ab9e1ceb4025882cb",
      "cc90806385914780b118f5e7a53ceb0b",
      "8cb27a70bee141af9f3b8f23c109c6a1",
      "92fdfda2ff664eab85d6e3e62e211bf6",
      "e1b44bfb66384129b90810b12b39a817",
      "07170fb6f5844aa0b3f5106ca84d9c4f",
      "4d4a1088102d46d3a4008b7b6d5ccb0b",
      "393a45754ac8470ab64b76f6e5603137",
      "bc345787e8544001b56def46bda72ae1",
      "b5ff5b3f5c574b98a55649cce818241c",
      "7c904626fd244b268bda5a0529967754",
      "6735cd7560fd41fc9ca5b04c9b1e6f29",
      "9c6da775adfa4dd89e71dcb165211c95",
      "8eb5c5c2a8e54b4f9e67170b208d501f",
      "a1760f11abdf405694a9ccc45b112aa6",
      "26eda275b2f4422b80d6a39c38c1b05c",
      "5d3a82a8084742f8bcdd434b9b4cca90",
      "c13cdba620ba466dba96cf90e0aafef4",
      "ca6be4a1cb2f42938735e7696b01a427",
      "e7fe3a4e41e040088c41f9ed00501cc3",
      "75e5904400f744aab927a70306f0afe0",
      "6aa59a55aa574b5eb1fbfaccdb7371ea",
      "c516702ff7654fe4bce0032bcad688c6",
      "ed1fac1d72b44e60a5eb83faae08290d",
      "64f73a3ef3814b96a397157662d898ae",
      "4c4bcc54417b453d8969066de08d5326",
      "89d196b5d7ad4ba7936c0f7d0dece96a",
      "130f319b5d6244be8bc5f54807047eeb",
      "c8c436b9facc4a729fe1118fc2d38c16",
      "b77a062fe28e42d49baf9a065ea1c917",
      "06eb0b1d0a444761bc6fa7d7ff3ac564",
      "1675aa310d0846e69349a8a94a66e80d",
      "c8807ac6f1704c5d855368b700a4098d",
      "22834af2617642bbb60bb42a71fdc281",
      "9e816b879d5f424799e7670bc5121b8b",
      "7b887692ab2f4fbca2c5b0349e1a15b5",
      "18e8df9b5db046b59d6f573d000bd016",
      "e95cf91ed6054c64bb480930568da912",
      "9db8dc2632c04b1d97ab0fc97bddd59f",
      "564cc26fc5c143ada9594083b80bf9df",
      "3923eaa0209942a682602a21b472ff3e",
      "bbf5c22e4184492fbd2ed790b6187330",
      "40cbe29e91844815b95c75ad74e4ab93",
      "0dd379f1cd3241d1ab0cf6e0c1dbdc22",
      "392f14ec99a94d9482c7d8c617417760",
      "4b0e297feff44b628ae1ae2cdf9c0088",
      "1af72c4e32354731bc29a08d711d298f",
      "3b5a0ffd92b045d5a1173c02d6bea026",
      "a05c898a511540059230558838536444",
      "a005b8def7684e93b7de8d414011e56c",
      "95d005c048d64b1f8757578ab8777901",
      "bbeda96acd2a42b790f4336d04b42d78",
      "e5e64d6a461c4fc583c07c5ab61ff310",
      "0283bcb068694edb8f2200899f00afa2",
      "ff02598dfcc146008f5a8c7f5b794537",
      "fcedb668ec584dd78099fc4b35060aa5",
      "322d333c29ad4c87bb99f71951bd29bf",
      "6e7fcac5e337440786b709b710714ba3",
      "03e64b9c148843e59c6b19f1bce40503",
      "515a5a8488364afabd0d76e71b7e48b9"
     ]
    },
    "id": "9j-ESwhpCHyS",
    "outputId": "f8ec417b-8b63-4aee-9672-f6ae10c3817b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model             | Model              | 379 K  | train\n",
      "1 | loss_fn           | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy    | MulticlassAccuracy | 0      | train\n",
      "3 | val_accuracy      | MulticlassAccuracy | 0      | train\n",
      "4 | train_f1          | MulticlassF1Score  | 0      | train\n",
      "5 | val_f1            | MulticlassF1Score  | 0      | train\n",
      "6 | test_accuracy     | MulticlassAccuracy | 0      | train\n",
      "7 | test_f1           | MulticlassF1Score  | 0      | train\n",
      "8 | test_f1_per_class | MulticlassF1Score  | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "379 K     Trainable params\n",
      "0         Non-trainable params\n",
      "379 K     Total params\n",
      "1.518     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfb7ee0f0ff4a228f4e8b92dbe5eecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b48e1969d6458092fcba8495ff0a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07170fb6f5844aa0b3f5106ca84d9c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3a82a8084742f8bcdd434b9b4cca90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130f319b5d6244be8bc5f54807047eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db8dc2632c04b1d97ab0fc97bddd59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a005b8def7684e93b7de8d414011e56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_acc --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3950226306915283     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       -- test_f1 --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3950226306915283     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_loss --      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.5811043977737427     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_0      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2749004065990448     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.46226415038108826    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_2      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.27757126092910767    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_3      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.39444443583488464    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_4      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48748353123664856    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_acc --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3950226306915283    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      -- test_f1 --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3950226306915283    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_loss --     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.5811043977737427    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_0     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2749004065990448    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46226415038108826   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_2     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.27757126092910767   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_3     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.39444443583488464   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_4     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48748353123664856   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples = [(conv_Attention,None),(conv_Attention,conv_lin_ffn),(gru_Attention,lin_gelu_ffn)]\n",
    "model, _ = train_model(num_labels=5,\n",
    "                hidden_dim=12,\n",
    "                max_leng=60,\n",
    "                attn_ffn_tuples=tuples,\n",
    "                ffn_dim=24,\n",
    "                batch_size=16,\n",
    "                num_repeat_modules=2,\n",
    "                train_data=sst_train,\n",
    "                val_data=sst_test,\n",
    "                test_data=sst_test,\n",
    "                max_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a8cc43ab6ea64d0f8d168a612b58f2f6",
      "9b2b1125b0224dc3bfc72bfe4c1cd937",
      "ca67941c337c4facbd98b9637c8d7e96",
      "6a4d85b4c97642e4ac6ee1219cae9a03",
      "9cd7931d90904dd0a9532f804557c6fd",
      "211b2961e0b243f2a15e480c3a20e46c",
      "d237b416c404423a83a8ebba8c922738",
      "cf3635a9cc004d8d9007c0238239b489",
      "efaaf1defcc44f2a91e7210d60feb63c",
      "e4686edefb084b6389e0a9ad08de0c90",
      "676dc5ab8c71451798cd2ca1b260c05d",
      "91619d103e5d40d4aeed8c4acf6e708c",
      "9a4a45f7eb5c4cb8b3370e0140b2e904",
      "2a611c8409e44c9e9087875c01298d00",
      "17d2fcda026b4840b06f8ab5233bf63d",
      "a238b77b5a944a6897654a003f7f2fe3",
      "d84d88aaa2d948a7be5e8347e9e11e93",
      "1ae1aa7b02d341fbbfb86f6594cebfa7",
      "1ec1dc6506ab405895e7fa5f3584f824",
      "689d42992936461bbec4747067bf329b",
      "890916d4cc434e5d9bde30337cc2ded6",
      "73b0c998c6e2409ab39b75df07df4657",
      "76ff2397ddfb4a38b02dde542a0a0776",
      "6b46da9b0662487fb3296940e54393e8",
      "015fc2734d324bdd94d6e07492fca0c2",
      "1ffba8b4487047f1a7edf56c1c7d5b48",
      "a02e259f31d14ad29a13cc60a37829a0",
      "985ed620fc95458e8fddf455e1670566",
      "da6fa3908d7a4270b8264a0e0e37f4d4",
      "82aa8a8e88944670b1dde5cb63284b68",
      "8f061a1244da406e84ee1c73dd1a73eb",
      "0b443b24f5864c5699e7786bbd748ea6",
      "42dd323e29d44a88bb215517ac4c77a4",
      "e7a02ac82a2941f9baba3312ccceacad",
      "aa5dbac559d94e8098eb3d96e59a08e1",
      "f4459594e1ce415b9b9019be5b447335",
      "22388411aab5459f83ac1f896790bfc0",
      "7a40bbb68e1d45fdbb23488a9a0b287d",
      "07ab0f1d299d42ed9cb7e68a153c9363",
      "e511b7bf5e0b40dfa387e03dceaa27c9",
      "a41d83c528c8413692856a0904dc609e",
      "0ea59883b4f34bb7a515956dbe18e3e3",
      "2a8447a7ef2c4a5c9f916271164c0b5d",
      "4bed9aa6bf644948959d79044df66b76",
      "d5a3e66f7fd042698ad4e5471441b7d1",
      "326f3d7f3022402795d37cda5dfb8dc8",
      "a7152106a37e47eb86f994c0de244054",
      "78ec9ac375be4869ba796a6f6ed883dd",
      "4ed09246ee1446d88027b07873d9079c",
      "700be771c49542db86136e90c1c80065",
      "98b8eae82efd4a619c2685c8854cdd63",
      "03da4a4b43a544d8a77ec751ca5cf119",
      "718404eb7f334050a11311462db09287",
      "d76999c4bbe94096af828da02de91b35",
      "698b0715261f416ab868291317aae713",
      "0353f098ecdf4262863ff702c2ab9fa2",
      "04783f70e117468291fca82f49fa6a23",
      "b6d743460560448f8900ea413946c575",
      "3c97c77d6dc74d6e88af9992d02ec1f7",
      "01279c2888e64ea0885887b3a87bb8bf",
      "1f166229e89d4ef7953284f75959d1ac",
      "5cdb118441564ab98ee0bf9ad9f23f71",
      "4f26b7bf3f504ec9af65e7f2212e1a41",
      "bbdab6328ac7449a93088394547a52b2",
      "590f4f4699a74237ac60e72d273ac726",
      "dced0c2a60b44ef2909a882513e0cb3f",
      "00f37d210221400e8cc32893f8035b4f",
      "2d01ae9370b2466b85f234ed8fd55614",
      "7ec5f628ca48464e9c19eb2dad6207aa",
      "8e6c5f8753724e4e83c738d56d85ea78",
      "3a4e0e53c6f9415db1704fa81785d0b0",
      "4ad940b87fc04a3bacd15fc481e957e2",
      "cbbebc639e0346d7b9d744677365d7f2",
      "3b89edae500142b0aa5ca30c2af5caa6",
      "ec34f931f80d4e879898e39af9fbe9c9",
      "20d70ea325d14cd4821093b9c4db03b8",
      "d58232019c794f2c801c174cdbbec653"
     ]
    },
    "id": "WFlrNoxyfIni",
    "outputId": "0f09c96d-d7d3-4bac-d084-12774549fe41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /content/checkpoints exists and is not empty.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model             | Model              | 509 K  | train\n",
      "1 | loss_fn           | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy    | MulticlassAccuracy | 0      | train\n",
      "3 | val_accuracy      | MulticlassAccuracy | 0      | train\n",
      "4 | train_f1          | MulticlassF1Score  | 0      | train\n",
      "5 | val_f1            | MulticlassF1Score  | 0      | train\n",
      "6 | test_accuracy     | MulticlassAccuracy | 0      | train\n",
      "7 | test_f1           | MulticlassF1Score  | 0      | train\n",
      "8 | test_f1_per_class | MulticlassF1Score  | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "509 K     Trainable params\n",
      "0         Non-trainable params\n",
      "509 K     Total params\n",
      "2.037     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cc43ab6ea64d0f8d168a612b58f2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91619d103e5d40d4aeed8c4acf6e708c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ff2397ddfb4a38b02dde542a0a0776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a02ac82a2941f9baba3312ccceacad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a3e66f7fd042698ad4e5471441b7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0353f098ecdf4262863ff702c2ab9fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f37d210221400e8cc32893f8035b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_acc --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2964800000190735     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       -- test_f1 --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2964800000190735     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_loss --      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.5512807369232178     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_0      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43967124819755554    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15866129100322723    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_10      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3428892493247986     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_11      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4580000042915344     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_12      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.29192546010017395    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_13      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_14      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.017004577443003654    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_15      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.007830853573977947    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_16      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_17      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6001644134521484     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_18      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09200283139944077    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_19      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.005240174476057291    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_2      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32866305112838745    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_3      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0015308074653148651   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_4      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35183316469192505    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_5      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0677146315574646     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_6      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09471556544303894    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_7      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1620788425207138     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_8      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_9      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.003338898066431284    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_acc --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2964800000190735    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      -- test_f1 --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2964800000190735    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_loss --     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.5512807369232178    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_0     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43967124819755554   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15866129100322723   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_10     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3428892493247986    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_11     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4580000042915344    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_12     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.29192546010017395   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_13     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_14     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.017004577443003654   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_15     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.007830853573977947   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_16     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_17     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6001644134521484    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_18     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09200283139944077   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_19     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.005240174476057291   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_2     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32866305112838745   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_3     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0015308074653148651  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_4     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35183316469192505   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_5     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0677146315574646    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_6     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09471556544303894   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_7     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1620788425207138    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_8     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_9     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.003338898066431284   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples = [(conv_Attention,None),(gru_Attention_2,conv_lin_ffn),(gru_Attention,lin_gelu_ffn)]\n",
    "model, _ = train_model(num_labels=20,\n",
    "                hidden_dim=16,\n",
    "                max_leng=40,\n",
    "                attn_ffn_tuples=tuples,\n",
    "                ffn_dim=24,\n",
    "                batch_size=16,\n",
    "                       lr = 1e-3,\n",
    "                num_repeat_modules=2,\n",
    "                train_data=train_dataset,\n",
    "                val_data=val_dataset,\n",
    "                test_data=test_dataset,\n",
    "                max_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "19de74770b5c44e987588660a3544eb8",
      "576de64781724ceba00d5f9ed29e1758",
      "5d00a9a98bc9489c84d28544eea85a3c",
      "5b4526f3c0fc45e98bb46810b8df2eca",
      "1be738e27a184fa8af9065856ea0d74e",
      "227f0cf7826e4be6ae4b210be1c1da5d",
      "0c2f5e8bdf6946d6a0534aa8244c2d89",
      "a48169234e784004aa692817ce151659",
      "9f969433db804056adcbcd490f183bcf",
      "5d7f8799c7ea452cb12177b10b5796f7",
      "597d6cb5d03d4f19b34d4adc4c93a248",
      "93a5c6acb4d9404a922fbf31e4320fdf",
      "28d9b8a92ad6454cac6e804f20c5833d",
      "f7b1af46a9a545b89087b8fc57694fb2",
      "c627343248fa459da9e8987d404c0193",
      "38983e6114cd4a1b95763766cac99306",
      "3a15d5e34a00411ab056dbd20b64f80e",
      "d7273bef491c49fbab2dfae44a4c8243",
      "5f9424d35c774e3aba75b3dc4f6009ef",
      "d5863dbc66c34f80a80e025854b29393",
      "c7fa0ec4a049440e94f7f675743b093a",
      "8173e0fa2e274814a6841981871ceb1a",
      "3976c0bcd28449e9aa84363cff54ecc3",
      "24e931cc6cfa4c39ad0f17a443fd220b",
      "65863a1e3e57431bbc36e3d577f79cab",
      "6f4948ad19e24c9b9cab855fca01dd4a",
      "931d52f209ca4176aa2afb89cea8ad16",
      "015ba4d2115146888ffd6156c8f92c4e",
      "5a1de29442e040c08b0a0a58da66f9d0",
      "8ba8d67ac10a4dfba3e3f330da64888a",
      "cc97d2555fba49979ae3581cbe06853a",
      "0fcd2d99a05843f588e8b8ee4b907938",
      "6f559bf8a6634196a067465d66833525",
      "5c1f9a544003427b81b3a4cfbfb78a91",
      "09d18a07fa5d4bb79691c2f165426d65",
      "e35fce87911f4e99af61898f0238033f",
      "ebf8c64d18da462b824fbd4ff9bfd1a3",
      "32e12767ca954c2f99fec412b30c5b3c",
      "9a419ee32f634f5a84b3c5845df93774",
      "55173325806240108b61986f638b1a3a",
      "b1e6607984484268bc291d28e9f3c9c3",
      "86a0e370807e46958488ec7dc2979b1a",
      "33e658c835e7471293c9d1d21a0263a2",
      "71f9bd282ac941b2ab1a7d080457a0a1",
      "a0cc18374e884c3a98537fa6ce331f46",
      "7d4992868f4844ccb576f00f70f99383",
      "f49bf782d7aa4eae829bd110f7f4a536",
      "bcf48a97d60640a6b9a3260eae5bc54a",
      "3cfebb02fbac4cd1b36bbe8d9dd1f5b9",
      "92a6d2a1b9744cf3b5c437990c14c9e3",
      "9fb65cdb7ee6400b9ec9f899b494d848",
      "05f3893a9d6d4e33a4d1529e07cf2817",
      "ea6c524ab83547fba4d343782c6e8f57",
      "7d1a3d3a8c7b46bc9c34a21b4f6a383c",
      "a60a1550844c446ca96d45cbdfe1df26",
      "7abef7f41cb04439a9f823c8434fc2ad",
      "32ff85650064457c8ed386c044917b41",
      "09ba3171c2364b17a671262aef3eaec7",
      "fed674f2519a4be29fb66ee3ddf5d83f",
      "447d7b2ea3524b99bf2013e92b42a1bd",
      "573a0cd576484f0ca0e220b94c988869",
      "edc8ea1972564adcaa1f78edbd7ef688",
      "382464b986f641d69b89563a55bb11f2",
      "64f77c887ef44a278a608a37636fda9d",
      "359b509907fb4da88157cb09bb5bb9e5",
      "2f0d46c0d3164383ba005ef1181a0204",
      "002d11fab0cc4444bd5a7b0cd05429c3",
      "e0519df372da4747947c9f78aa814005",
      "c7c58213ea1d4b4894745bb9b0d2cad3",
      "31df3ba92d5546bea55acadcdae3c202",
      "c35623a76886414d941bb2257e5a4d5a",
      "0f2e0bac8d3941938709fc0a9880e30f",
      "f82d307033bb4552999b374b773baeb9",
      "f599fb930e0542da9addeb67db9c23ec",
      "071ba7d40ae446e784a35d0220c813f3",
      "d3f440e7fbdf4ace91d208e7e87ab4e8",
      "7305e7888f3a4ef19c69df4340753fe3"
     ]
    },
    "id": "nQ35VMnCh8Oo",
    "outputId": "13eab260-2c99-4673-a2f3-1f52a6fb6bbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model             | Model              | 500 K  | train\n",
      "1 | loss_fn           | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy    | MulticlassAccuracy | 0      | train\n",
      "3 | val_accuracy      | MulticlassAccuracy | 0      | train\n",
      "4 | train_f1          | MulticlassF1Score  | 0      | train\n",
      "5 | val_f1            | MulticlassF1Score  | 0      | train\n",
      "6 | test_accuracy     | MulticlassAccuracy | 0      | train\n",
      "7 | test_f1           | MulticlassF1Score  | 0      | train\n",
      "8 | test_f1_per_class | MulticlassF1Score  | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "500 K     Trainable params\n",
      "0         Non-trainable params\n",
      "500 K     Total params\n",
      "2.003     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19de74770b5c44e987588660a3544eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a5c6acb4d9404a922fbf31e4320fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3976c0bcd28449e9aa84363cff54ecc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1f9a544003427b81b3a4cfbfb78a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cc18374e884c3a98537fa6ce331f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abef7f41cb04439a9f823c8434fc2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002d11fab0cc4444bd5a7b0cd05429c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_acc --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2842000126838684     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       -- test_f1 --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2842000126838684     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_loss --      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.647862195968628     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_0      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4267321527004242     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20317740738391876    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_10      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2883758544921875     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_11      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4413203001022339     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_12      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.26388272643089294    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_13      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.027234042063355446    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_14      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.02044728398323059    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_15      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.035225048661231995    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_16      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_17      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6085911393165588     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_18      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12109978497028351    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_19      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01413427572697401    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_2      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3263643682003021     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_3      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03589232265949249    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_4      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3756789267063141     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_5      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06534870713949203    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_6      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10834473371505737    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_7      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19527500867843628    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_8      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.016364699229598045    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_9      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.011251757852733135    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_acc --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2842000126838684    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      -- test_f1 --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2842000126838684    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_loss --     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.647862195968628    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_0     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4267321527004242    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20317740738391876   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_10     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2883758544921875    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_11     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4413203001022339    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_12     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.26388272643089294   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_13     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.027234042063355446   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_14     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.02044728398323059   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_15     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.035225048661231995   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_16     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_17     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6085911393165588    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_18     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12109978497028351   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_19     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01413427572697401   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_2     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3263643682003021    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_3     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03589232265949249   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_4     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3756789267063141    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_5     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06534870713949203   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_6     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10834473371505737   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_7     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19527500867843628   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_8     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.016364699229598045   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_9     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.011251757852733135   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples = [(gru_Attention_2,None),(gru_Attention_2,lin_gelu_ffn)]\n",
    "model, _ = train_model(num_labels=20,\n",
    "                hidden_dim=16,\n",
    "                max_leng=40,\n",
    "                attn_ffn_tuples=tuples,\n",
    "                ffn_dim=24,\n",
    "                batch_size=16,\n",
    "                       lr = 1e-3,\n",
    "                num_repeat_modules=2,\n",
    "                train_data=train_dataset,\n",
    "                val_data=val_dataset,\n",
    "                test_data=test_dataset,\n",
    "                max_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "daefc9a4430044f49bf90a8f0a27ce18",
      "fa59fcf67bbc43e6b5e8783063ccc91e",
      "153d5b1d99984134ae7d2f973a2f000c",
      "3bd228c607d94a6ba10e34b56eb0f4fa",
      "b64091e222104249b4cd705f81ded6ce",
      "2392ca8e51184750863742aa2d0da62d",
      "603a059b56864ab5a3fc237491b8d33e",
      "badba109d6844e2e8a49f46493a41400",
      "6fe96eb8411d471387cf378f402f213d",
      "0566a2e9055b4f45b60915d3ef5fce3d",
      "48975d858297468cb50b44173cb30c8f",
      "d44d25c0fd7a491283c7ea0bc2186e17",
      "d3f39723c52f42fb994931fd361805cb",
      "1e54774d1e554b939e0abcd292e38a5e",
      "30a4c21a4f8043f09af93b68117ee4e6",
      "53e2170eb3424efd9a6d0165a3576509",
      "04887dc4876b4ffd837cfe902c18cae8",
      "5f070d7b5b0d42aa95b72222f62a56b3",
      "82ae6036437f4865ae646966ba4060c8",
      "877dbcf26572487bbb7f8233adae1c07",
      "f346933414dd4d509447fbc7e6928bc7",
      "181156a7af57493b89465673aa1a14d9",
      "d8c9f13d892e4e94b067bc44f6c89bcc",
      "e88be426f0bd41d89e2f397e7393dc9f",
      "38999afe69094779a21fed8f204de006",
      "17ba556aa1824bccbb2206bdf652704d",
      "21613bc68a1d43b6b989c4424250a47a",
      "5da732918f054ec3925f9209dca7f5fe",
      "8afe95b8ecbf4244a056856842cc7243",
      "0b79ce2274f74bfc940a7f2f8616ffd8",
      "ae8630da6ee64767b1717c99ca645e13",
      "4bb8f33c0ab947a0a22a1697fa325dc2",
      "7256d18192964f1a971498e8e3567549",
      "289635c157474b13be40e61f6fea441d",
      "49df45314f954605b6b3eb4270c7254a",
      "4aedd27f9f524fac849c32d61766ce61",
      "a4b440f8a17148eea91ce405f0f67214",
      "11e5702049624fb2a7a285cd59fe4b7a",
      "6e140bde23a94b9d9fcbbd2746669a37",
      "57b669acd8c6403aae0efbcec7ac34b8",
      "0b30dd07eb794913b59b887da3917f28",
      "46b8fb09b9a94de18d9bf34c18d91aef",
      "e7f66dca8dbf45a6b01ddc0a2f8fd2ce",
      "c975fe32c64948ed9a7da0509c5ce351",
      "a4a18e40340f491da9f1077400b9d0cc",
      "8cbcf78af0754be8a1aa016f2f81d7e3",
      "444db10023554765b84768d8fa5e3520",
      "6a475fe6fb2e4a91b89e3e0c79c39aac",
      "7a15206835554d42a1532ecf62bd92dd",
      "d88a8c0dec1f458b9dacd972ad95d295",
      "30cd67757b4c48ab80dffe2eca7394c9",
      "5c9e9e07e55e487dbe9aff95e9ef6483",
      "5ea5fb36399d4bcda7ed63bfc8a5b1df",
      "6e4edaf8b5f949c791758d27e084c363",
      "38c0bc3db9af45f9b07ecf7c13d030fc",
      "8ead0903b1c24400932a93b229434494",
      "c1d5348469094ce08b805f552d0eaf77",
      "1f03cbf2506c4fe9964513596bfeca24",
      "ab67afa3e0e54b3faed53108776c1f89",
      "91bf47a9c22943309677388e1fd17cc8",
      "1979b9974a4541929b1d70f76b20c3e6",
      "979e66e5b8f3499aa0363adc85ef1034",
      "7492b7136d0841069da68aabc2804291",
      "bc578118e7f24b15addaeb9b791873f5",
      "3a5e2370c6e044cea3e5c47253df0447",
      "54091147304e44d5ace10a9da6625fd5"
     ]
    },
    "id": "a3jBxeV-jTr-",
    "outputId": "6822fa9a-3a97-482d-c55c-52fa0f4dd3fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /content/checkpoints exists and is not empty.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model             | Model              | 500 K  | train\n",
      "1 | loss_fn           | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy    | MulticlassAccuracy | 0      | train\n",
      "3 | val_accuracy      | MulticlassAccuracy | 0      | train\n",
      "4 | train_f1          | MulticlassF1Score  | 0      | train\n",
      "5 | val_f1            | MulticlassF1Score  | 0      | train\n",
      "6 | test_accuracy     | MulticlassAccuracy | 0      | train\n",
      "7 | test_f1           | MulticlassF1Score  | 0      | train\n",
      "8 | test_f1_per_class | MulticlassF1Score  | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "500 K     Trainable params\n",
      "0         Non-trainable params\n",
      "500 K     Total params\n",
      "2.003     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daefc9a4430044f49bf90a8f0a27ce18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44d25c0fd7a491283c7ea0bc2186e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c9f13d892e4e94b067bc44f6c89bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289635c157474b13be40e61f6fea441d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a18e40340f491da9f1077400b9d0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ead0903b1c24400932a93b229434494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_acc --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.296860009431839     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       -- test_f1 --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.296860009431839     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_loss --      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.4367027282714844     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_0      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.44590118527412415    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20573294162750244    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_10      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3054457902908325     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_11      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.47703301906585693    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_12      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2918586730957031     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_13      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_14      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_15      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_16      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_17      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6333659887313843     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_18      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_f1_class_19      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_2      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34103962779045105    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_3      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_4      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3859362304210663     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_5      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01316511258482933    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_6      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09737047553062439    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_7      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14729776978492737    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_8      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_9      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_acc --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.296860009431839    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      -- test_f1 --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.296860009431839    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_loss --     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.4367027282714844    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_0     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.44590118527412415   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20573294162750244   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_10     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3054457902908325    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_11     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.47703301906585693   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_12     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2918586730957031    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_13     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_14     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_15     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_16     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_17     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6333659887313843    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_18     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_f1_class_19     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_2     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34103962779045105   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_3     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_4     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3859362304210663    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_5     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01316511258482933   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_6     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09737047553062439   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_7     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14729776978492737   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_8     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_9     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples = [(gru_Attention_2,None),(gru_Attention,lin_gelu_ffn)]\n",
    "model, _ = train_model(num_labels=20,\n",
    "                hidden_dim=16,\n",
    "                max_leng=40,\n",
    "                attn_ffn_tuples=tuples,\n",
    "                ffn_dim=24,\n",
    "                batch_size=16,\n",
    "                       num_heads=1,\n",
    "                       lr = 1e-3,\n",
    "                num_repeat_modules=2,\n",
    "                train_data=train_dataset,\n",
    "                val_data=val_dataset,\n",
    "                test_data=test_dataset,\n",
    "                max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720,
     "referenced_widgets": [
      "62d3579a7410463f8e8494ebd83f07de",
      "c631c0e0947a44628c4428da01a8fc39",
      "a0efd4f71c4345f7b3e5c482437b0897",
      "0bc6e24693c440738ef7dd45f1f65b16",
      "d7ce92746e0e4787860cbf475c4d43e6",
      "eca568f4a52546cfb028f84cb88729e0",
      "2d6c38b8369042a1b6a89189c5bcc906",
      "fd6fc952c63e45559f40539b30e99df2",
      "383c580804aa4de4ba5da67a2ef72cca",
      "638f2f821ecd494b99052988d9b40713",
      "e7c258f5a19245fa9f4e5996019ae630",
      "e4df03244cc445f8af41278f8069a78a",
      "7baf626b6f844824892ab00e52af6079",
      "9826e0e0f3814403a377855a9b5002bc",
      "2e164cefc0c2419bb984c9ee4ae00624",
      "979de6d684fb4426850f64fd725b2571",
      "846dfa4223b74009a1bafa7fbf3d63b5",
      "f8cda37d6f3346c0bf93ec048233446f",
      "42ac130ca3694f2292e52b6ead927a25",
      "d35709463a85490b8e67c54ca550c4a4",
      "bfcde77ab27743c9aae7d3349d79915e",
      "234bfffca34745b387ddc0357799e7d9",
      "c207c34544a546b6ac1583971d437a22",
      "cf3292a4ab1b49cda528bbdd88d41a92",
      "c8036c99950147d0a3850865c51a0f54",
      "4774d6c0f4e747378f6a761f5293731c",
      "dce1a08a30bc4b98b30f85c453f48651",
      "18e841dfe1df410895e93663a1bd9f11",
      "c9581c3e561644e1988749dc11e4dbae",
      "7d83e05635fe40a1a9c32524728d9a59",
      "7caeaf10bdb84038873de9879ddd85e0",
      "a9f1a27d623c419b97a3bb5be9e3fad8",
      "8248137cfd964fb8af641fa3525ac56b",
      "884a01dbd7754b7c8bfc98c3b132b1eb",
      "168cf4cc99464d62b8f8694dd5e5391a",
      "125c23260b1342f6a078c2ac6db83f49",
      "61bf7164f00c4c1fbc735550cf4a802c",
      "d4e389d6a49d4b518f885c10486e251b",
      "242d5fee8e9340d895286f634e2af16a",
      "de584bef76fd4f3289bdc21b498ca61e",
      "ed4b2853c9cd4375a5cf78b4a5016486",
      "4f044b2888c0431aadb450166dd0d536",
      "a9c27e031dc74320873142ec240c5856",
      "f31ac00e07dc4ed982bce865c69548ef",
      "438ba53629324911be97a0dbc09fb769",
      "48c2da681d634ae6be485ba7de9104f6",
      "b1f94fc220164659903656575cfa16f1",
      "35d64020603a4409be5731f78fa1a729",
      "dc59864b745e4a1381f4c4e8d3dd016b",
      "9df83c048da94ff4ad5c9fc1d0f9fe74",
      "2a6b31f100264b06ae511932d078743f",
      "c16a07c2f40c4fd0b4b91512e0a161ca",
      "3f3344ea4267471185dcb9f6b1ee4b11",
      "98bc7cf385164eadae0de28f5244cb7b",
      "5c1e0e9c8c9147e08be74c234c45aab9",
      "9292543b0da74c13b8eeac98a17a0e02",
      "e8497b201251479ba993e6f7d3b8a8bb",
      "68e0544272744bcfadc591fca925f16d",
      "c63d1039ee884c94b9da88f570d2a1c4",
      "90604847b6a44087be95b82225a07c16",
      "e5bba5120bc046cba18c552c891e44b9",
      "8cae3d12426a4b658d0950c46f4e6b14",
      "85a1b552d635449abbf68933bc453fd8",
      "9d5582bcc57b44c88325b7d99634327f",
      "fb2edb6dc11d4de48c377569d8644581",
      "0d018852b6aa4e4ca2362cd68bdcc2da",
      "4d6066124b9e4596ae0518dbcaf2fd4a",
      "2cc93fab55ff42b19e62d514b2adb6fa",
      "c9cdf1cef4b843df9bd715c78eeee4e5",
      "d01c1afc6f564993ae5b7675d6f186ea",
      "b50dc624610c44d28368f687f4932a85",
      "f4c5e5c3eb804868a202a96fef6855dc",
      "745e50b797d045f78ac906eae7c82ac7",
      "f7053f1c46cb47238369f4cd8acf75f0",
      "41edad4122f3460faec30872ef2acfcf",
      "9e4e01d227514041831600145d3bd227",
      "3bd902b82ab841d0ab55ce48c544df74"
     ]
    },
    "id": "ZuqsQqewaQdN",
    "outputId": "3418c0af-28e9-4b6d-abdc-52cdcbc2e1ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /content/checkpoints exists and is not empty.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model             | Model              | 591 K  | train\n",
      "1 | loss_fn           | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy    | MulticlassAccuracy | 0      | train\n",
      "3 | val_accuracy      | MulticlassAccuracy | 0      | train\n",
      "4 | train_f1          | MulticlassF1Score  | 0      | train\n",
      "5 | val_f1            | MulticlassF1Score  | 0      | train\n",
      "6 | test_accuracy     | MulticlassAccuracy | 0      | train\n",
      "7 | test_f1           | MulticlassF1Score  | 0      | train\n",
      "8 | test_f1_per_class | MulticlassF1Score  | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "591 K     Trainable params\n",
      "0         Non-trainable params\n",
      "591 K     Total params\n",
      "2.367     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d3579a7410463f8e8494ebd83f07de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4df03244cc445f8af41278f8069a78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c207c34544a546b6ac1583971d437a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884a01dbd7754b7c8bfc98c3b132b1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438ba53629324911be97a0dbc09fb769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9292543b0da74c13b8eeac98a17a0e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6066124b9e4596ae0518dbcaf2fd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_acc --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8705000281333923     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       -- test_f1 --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8705000281333923     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_loss --      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.42332208156585693    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_0      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8764312863349915     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8639705777168274     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_acc --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8705000281333923    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      -- test_f1 --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8705000281333923    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_loss --     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.42332208156585693   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_0     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8764312863349915    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8639705777168274    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples = [(conv_Attention,None),(gru_Attention_2,conv_lin_ffn),(conv_Attention,lin_gelu_ffn)]\n",
    "model, _ = train_model(num_labels=2,\n",
    "                hidden_dim=18,\n",
    "                max_leng = 1200,\n",
    "                #num_heads=2,\n",
    "                attn_ffn_tuples=tuples,\n",
    "                ffn_dim=25,\n",
    "                batch_size=64,\n",
    "                lr=1e-3,\n",
    "                num_repeat_modules=2,\n",
    "                train_data=imdb_train,\n",
    "                val_data=imdb_test.shuffle().select(range(9000)),\n",
    "                test_data=imdb_test.shuffle().select(range(9000,25000)),\n",
    "                max_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703,
     "referenced_widgets": [
      "ad860e0156fd4c8eb351fb6b361a05ca",
      "329156c43baf41f99359bb98fae52182",
      "c982100718fa42deb318848126b13c61",
      "e86311f0b5804f6e9a8c5640c0c66457",
      "2954ec7d22ce40a38115991c4096b4df",
      "80be375de3cf4b21bad1c2dac7de8c4b",
      "70c500d7f15248cc88828bdf3a76c3da",
      "b06fa51d9e3c411b93ab6123eed0eb49",
      "be2a29163fd341909e92cee2c839fe93",
      "76d08dbb0d244043bfba3b2e405ff4a7",
      "28f5a876e67a49e0b5c7c59c9c2c2891",
      "44a83ed519674d58918b07dfa712081e",
      "81098605108843d78472f2787055ffbc",
      "e8532655cb394c8ebf69ba6d22b61ba8",
      "c2d2cac6c464466db669b3339c7a4853",
      "78b52b947a9d4200a7e9ecc3fa8a519d",
      "22ff3522689548a3bb5f616371988080",
      "9605ccae6cce4608862ceea7440c8ade",
      "d585ff892a4242a3b9e3a07609da65bc",
      "15228e9a08c84f08b40c8d6d6ab71c8b",
      "6b68c117c9b243638de19db9aa0907b5",
      "90ac8989eace4e979783a9f792815a7b",
      "5eaa170386a842458486b4619cdc66e4",
      "0f738cbc4e7c4f3ca32f7ef759c86d6d",
      "28da3b99fab84454a35519ea4d95a557",
      "d897fa320af54245acc6fcd2739b6f7a",
      "6583074fde834e03ae91345ace24efb5",
      "4672130c40d94ef6ac58d883e2c8ffce",
      "2c3260db68504c218c6cb4a9595ecfa2",
      "c91ee6d58c284a95b360e6611370798e",
      "aeb71a2a89104c848ed41fc5006c5805",
      "3749f00671db47bc99467de4204711c0",
      "da9cf40a80304fe88b048ea10e5196e9",
      "af051737766947589e18254f5c2033d5",
      "74503ecec88842cfa69cbdb902b395fe",
      "ddef63dfe3e74ba49dbf6051bf722e0d",
      "fd0e5a4934a34d18ab88c4ca8ab3dc75",
      "bacfe422613b4c7780ad923450816994",
      "96404a5696b74049b8604e1dda45dac2",
      "552263c3e3134796b133fee0629de459",
      "104b92696a5f493f99011a406bbbf8c1",
      "724f1825077d413aae488ef453f01796",
      "db37b23e8c264d429698116875c4e312",
      "edb9866a75494a4487d81842fddfab72",
      "afe14a5d75754442b436f869793e3175",
      "10b836b9ae4f4bc1aa93f621e4b3850f",
      "ebf1114e2a31497986c31b83da854a1f",
      "3416f38e52144bfc9b9dcc911e67994d",
      "6bc4fbd76d424be3ad21868a0e8b2ac2",
      "052c6189baff44428005e75a67c4ba20",
      "5ac3ad33cea44f1d89b8efa158f32def",
      "c2425b1c9d9341beb50efbb635e125cc",
      "abc497f9b2d74edf8cde24195e210918",
      "01759022aa4343e990816c326582fd17",
      "2db05ad01af3415581d77854e595698a",
      "7ef31dc17e5b40a3b42263ced7d16a68",
      "98fa85b7d6a0489fbe67d54ba7708cf1",
      "e46b6f6e9e3a412ea2ee648e8f021ab5",
      "2039dc945068484fb87e33df60ddb211",
      "a4b16f6579a9422db8e9aef1da13c24f",
      "504deb75020145a9ba1ba72ea0815166",
      "7327e0b4d9de42c784468710f0e630a0",
      "82ec670a2bbf40979292fa4d9584cea5",
      "2b9eea82a8494e40a88c79bf470b93fe",
      "dc810c8593ec474fbd4095775728ba19",
      "a50adc3992804b2d9c8870d99b9015f0"
     ]
    },
    "id": "BWfRz87VlIZx",
    "outputId": "bb8b2624-fcc4-4f85-b8b6-6bdd7580270f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model             | Model              | 599 K  | train\n",
      "1 | loss_fn           | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy    | MulticlassAccuracy | 0      | train\n",
      "3 | val_accuracy      | MulticlassAccuracy | 0      | train\n",
      "4 | train_f1          | MulticlassF1Score  | 0      | train\n",
      "5 | val_f1            | MulticlassF1Score  | 0      | train\n",
      "6 | test_accuracy     | MulticlassAccuracy | 0      | train\n",
      "7 | test_f1           | MulticlassF1Score  | 0      | train\n",
      "8 | test_f1_per_class | MulticlassF1Score  | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "599 K     Trainable params\n",
      "0         Non-trainable params\n",
      "599 K     Total params\n",
      "2.399     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad860e0156fd4c8eb351fb6b361a05ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a83ed519674d58918b07dfa712081e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eaa170386a842458486b4619cdc66e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af051737766947589e18254f5c2033d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe14a5d75754442b436f869793e3175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef31dc17e5b40a3b42263ced7d16a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_acc --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8881250023841858     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       -- test_f1 --       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8881250023841858     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      -- test_loss --      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.28510233759880066    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_0      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8879989981651306     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_f1_class_1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8882507085800171     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_acc --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8881250023841858    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      -- test_f1 --      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8881250023841858    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     -- test_loss --     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.28510233759880066   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_0     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8879989981651306    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_f1_class_1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8882507085800171    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuples = [(gru_Attention_2,None),(gru_Attention,conv_lin_ffn),(gru_Attention_2,lin_gelu_ffn)]\n",
    "model, _ = train_model(num_labels=2,\n",
    "                hidden_dim=18,\n",
    "                max_leng = 1200,\n",
    "                attn_ffn_tuples=tuples,\n",
    "                ffn_dim=28,\n",
    "                batch_size=64,\n",
    "                lr=1e-3,\n",
    "                num_repeat_modules=2,\n",
    "                train_data=imdb_train,\n",
    "                val_data=imdb_test.shuffle().select(range(9000)),\n",
    "                test_data=imdb_test.shuffle().select(range(9000,25000)),\n",
    "                max_epochs=3)"
   ]
  }
 ],
 "metadata": {
  "cells": [],
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "name": "python",
    "version": "3.10.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
