{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXdL4Q0OYiUm"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning  seqeval evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vrq_gmU8X1b7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import load_dataset\n",
    "from evaluate import load as load_metric\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "2eba476c1e5e42b8bac8e6d6d2953fc8",
      "8c31e80782b44e7ba849631fa32ee6cc",
      "c639e466803649a081830f323a582a1e",
      "dd2ca92dab284645927be15ba78b114b",
      "690c8e7639b848119546a1a94088f6fd",
      "05b4394bfef54064909bcc3562e54b4e",
      "e928119f7d7f4e4d80ec14bbff92cecc",
      "5e398e2c9f3d47c294c3598c4e6a4651",
      "3c0223f9936a4a19b1164303718e1b5d",
      "5fba1990e21642029f90d07b11bd5344",
      "6a43186113ed44878bc30d7bed7ccd25",
      "354c7d9c69f24a7aacc3010ef40ce60e",
      "ba8c45c839114ca4a34add233a415d9b",
      "5822a7856ba045ac9f134bf50fc18f83",
      "6d4b5aa35aef477c98e3c205469cd5be",
      "ebd12bfa49164b89b1ca8d3e3630cccf",
      "4b9debb65ec44e40b7f2c338791f0771",
      "0fa27da3f83e4954baf8a1182c3f435c",
      "0e761ffa5e654817a83e3a9f0b89652e",
      "263c30f8b22042748543630497fa13fd",
      "cb675a0030ca46a1a31c8a1f8be4be46",
      "c4cf01b3c4d247bd819cdf2821bbcff7",
      "adcdee3b896d4faba4ca4b6c13282c6b",
      "6ddd4af594b94289804966b92a582f9b",
      "d2f18a6885bb4ee8ba258c12736de721",
      "327b3292cb5442ce98c09a94994240bf",
      "58dec98ec9f94a189eed7b7221d1575d",
      "138f4c8fa40a4bdb8dbe1d0a590e626b",
      "8f2837ecf52b46bd81c25875ec406315",
      "5193847a721f48e1a883db1c07a7db0c",
      "875ee60909fe4b1f94ff614c556ccf1b",
      "745a1ca0342747408f90754687d280aa",
      "721a3b0e79804b66b6dadaf1072bb349",
      "ca41204faa384963852f70f7d349a7dc",
      "fa92240b35bb49ce8db8de951df2845d",
      "f087fa8e14e246c9b41c6555a38a7aa2",
      "40522186783c4dec9cffcbd47c77eb37",
      "fdc838dde85c489087f38741ab510cbd",
      "676e6fdc0f2c444d8bc9c7ff8069c075",
      "07c95a6dd566479a800e5c756fcb296f",
      "191cabd70791493d96a0ab04bbeadca5",
      "36c4ac941a8b498d9d3f4e8806cc70c2",
      "10abc49fd25f441b920625e1e802c864",
      "05ce19c9a0ce49628a8fd129ed2046ce",
      "6e8695c2025e4d47b331a9dee5c15260",
      "b0935d18ebe9461c95ef3562a840fc82",
      "b97580ff839847e9bdb71e28f59eb80f",
      "9e68fb5a077c4e90a24a0e4baccb5fa8",
      "8880a32ba0394f6c886adab4a669cb46",
      "a4e2cd8c72fa4093999e3ca1b07714b0",
      "9fecd6863a1e4c18a2f9a5dfa9660126",
      "82d9bd9c74b84eda970ca205d8cbfe8c",
      "74d2fd329811409fa9f156c0a4247a7a",
      "3e63db947f94484d820ded146971dcfa",
      "f7889927b8e6458596a601d5260e16c6",
      "007aaf0122d24ae48ebbad69202d5bab",
      "cf2ee4f908564a07bdf467d2dff1a643",
      "fb00d4e6885748519b8437076581b032",
      "6c01275c82d44cf7989db8cb8f5a7212",
      "c445f163528b41da96fdacebf24192c7",
      "04f367bf54ca4595ad07d15433fab349",
      "b69441bdc9a744ada4b345f2f5ef3200",
      "452de981785c4bc58d120b99a97dd618",
      "7cda9b8ab85c4a9cb87a4373fa32295c",
      "647cc076e32549e794cb89b8dd79b3a9",
      "4aaa58a813a5421281fe04ba146fa5bc",
      "b63a131590c74a0a92f2e3b3baa9dc49",
      "d89df306ccd240599cfc26a86942db27",
      "1eace42fa62443f591c26c3e15e3655d",
      "004c28c853a94bdd83fa96f48ca9a2dd",
      "f37d2862b3f74ad89153c4f19cc29eff",
      "e7da94fbcd314a018d71033aad6b247b",
      "8dd9334e8212430ba2ccb49fe236dda6",
      "853315a37bf1412799e829643b32ab14",
      "e4029dd096ba4511886d1fae6c8ad9dd",
      "2e60aabea4684ed4a956908ad4821a96",
      "67d4b930fef34875bad06fe5b8279735"
     ]
    },
    "collapsed": true,
    "id": "IFxh5EsPCTXQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "14b10849-3ff6-4e99-9e0e-f3d259f165e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eba476c1e5e42b8bac8e6d6d2953fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/926 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354c7d9c69f24a7aacc3010ef40ce60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/309k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcdee3b896d4faba4ca4b6c13282c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001.parquet:   0%|          | 0.00/67.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca41204faa384963852f70f7d349a7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/116k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8695c2025e4d47b331a9dee5c15260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007aaf0122d24ae48ebbad69202d5bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63a131590c74a0a92f2e3b3baa9dc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"manu/wnut_17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3I3A1O6C1-A",
    "outputId": "e509c80e-2e2c-440d-e6ff-c73c877944b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3394\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1009\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1287\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Q68mC9oqEnIR"
   },
   "outputs": [],
   "source": [
    "# Dataset classes\n",
    "id2label ={'0': \"O\",\n",
    "            '1': \"B-corporation\",\n",
    "            '2': \"I-corporation\",\n",
    "            '3': \"B-creative-work\",\n",
    "            '4': \"I-creative-work\",\n",
    "            '5': \"B-group\",\n",
    "            '6': \"I-group\",\n",
    "            '7': \"B-location\",\n",
    "            '8': \"I-location\",\n",
    "            '9': \"B-person\",\n",
    "            '10': \"I-person\",\n",
    "            '11': \"B-product\",\n",
    "            '12': \"I-product\"}\n",
    "\n",
    "label2id = {k:v for v,k in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "447100fa4c0544069dd0738be3c15072",
      "8f0abc110bcd4277b4e2e6d040ebf850",
      "c89d19f4e19e4583a38dd20740113c75",
      "e645755f045f427681f695010d0157da",
      "5e13c295fea04f21906ea51d527ee7e8",
      "c41cfcd9dbf047b89bbde40cf27caaf1",
      "7423a890c08b4dcda264ef8f6926328b",
      "bd8ed0b9aaed4245ad93d9cf6e7c52b0",
      "e772d8dd696c42539eb1ca50c1873d9a",
      "3692d18f1dc44ba09dcf1e71828f4c3d",
      "b6d0f3f4f89641e4ba9dccee80296c25",
      "89163526b95e4975b3a4306d2622d45b",
      "df86721eaae84acd918d2b96691521c0",
      "2f78cda8321145d18aa06d5eda51eef7",
      "762e88d68879427e9a8dc1c44b6673bb",
      "716ac3f7beb9463782a94b260d284aff",
      "f5f34686fa0345b5aa1aaa216238326d",
      "ae6d58e50d4246bfaf77fe5e033483a9",
      "31c58b31d04143f2965ddaea966e5583",
      "d7f57199a6304a46a3f134b0503ed9b5",
      "bd14312f09394625b5367f31baa9c032",
      "2fc16ae102ad449bbdfedba73327e8df",
      "b30b2ec662774899aafe4d2fe095d77c",
      "9497db601cc9483c84bcb515f7b9b9b5",
      "f4cd314b62784f41befbed5461c89f64",
      "7ca5af8af5b04174b3175cc23e1755f3",
      "53b9bf2382e04bc6808f06aa14192d16",
      "39eec6fb12464f22835475a4eaecee6b",
      "4a901cb43674488f8495ed0370b73abd",
      "09f132b8c2224844b34a1ae1eda2c942",
      "d2b6e5ef837f4850afd34a106971eb8b",
      "ae1da933d2e8429f9e68bb82ef3dfbb5",
      "1173d08f2de74eecba490b1bf3e4fefa",
      "f6a496fca96c4aa78f523555fabcf422",
      "e152314b4a684af68a22d9f62a05e2e7",
      "4313b4884c644131ae86a3ee71997b01",
      "816c30a273f2477c8038a22b7b28abcb",
      "01f7ab983a564685a5a32107ced35e99",
      "57e6ee8888954dc781d3b96d9098f2b0",
      "9b531ef48cf24cf28918f91eddcfed53",
      "17ac245c871c4a42aa4e2eb8f2c18fe9",
      "12a892106694468ebd73b04e387f3d6f",
      "10896701e8cd46889d263afddd5551cd",
      "b0a145d0a71c4f5687262bfcde121383"
     ]
    },
    "collapsed": true,
    "id": "MJYcuoxAFPWu",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3f72ae0a-43d4-46cc-fc88-c41d2e1f5a8f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447100fa4c0544069dd0738be3c15072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89163526b95e4975b3a4306d2622d45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30b2ec662774899aafe4d2fe095d77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a496fca96c4aa78f523555fabcf422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2s6VkO1_NTa8"
   },
   "outputs": [],
   "source": [
    "def Preprocess_Dataset_2(dataset, split: str, tokenizer):\n",
    "    processed_data = []\n",
    "    for example in dataset[split]:\n",
    "        tokens = example['tokens']\n",
    "        ner_tags = example['ner_tags']\n",
    "\n",
    "        # Tokenize the entire sentence\n",
    "        tokenized_input = tokenizer(\n",
    "            tokens,\n",
    "            is_split_into_words=True,\n",
    "            padding=False,\n",
    "            truncation=False,\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "\n",
    "        word_ids = tokenized_input.word_ids()\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(ner_tags[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        processed_data.append({\n",
    "            'input_ids': tokenized_input['input_ids'],\n",
    "            'attention_mask': tokenized_input['attention_mask'],\n",
    "            'labels': label_ids\n",
    "        })\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "O5Fqo0rAIjWv"
   },
   "outputs": [],
   "source": [
    "train_data = Preprocess_Dataset_2(dataset,'train',tokenizer)\n",
    "validation_data = Preprocess_Dataset_2(dataset,'validation',tokenizer)\n",
    "test_data = Preprocess_Dataset_2(dataset,'test',tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J0nWNXSuZwVf"
   },
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "  def __init__(self, data, tokenizer):\n",
    "    self.data = data\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return {\n",
    "\n",
    "            \"input_ids\": torch.tensor(self.data[idx]['input_ids']),\n",
    "            \"attention_mask\": torch.tensor(self.data[idx]['attention_mask']),\n",
    "            \"labels\": torch.tensor(self.data[idx]['labels'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "968RT7n_f5hS"
   },
   "source": [
    "**collate_fn**\n",
    "\n",
    "متدی برای پد کردن داده ها برای اینکه همه هم اندازه باشند\n",
    "\n",
    "یک بچ از داده ها را میگرد و همه داده های آن بچ را پد میکند\n",
    "\n",
    "این متد در دیتالودر استفاده میشه\n",
    "\n",
    "در واقع **هر بار که دیتالودر یک بچ برمیگردونه این متد روی اون بچ اعمال میشه**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AW61SrZLks7i"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  input_ids, attention_mask, label_ids = zip(*[(item['input_ids'], item['attention_mask'], item['labels']) for item in batch])\n",
    "\n",
    "  input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "  attention_mask_padded = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "  label_ids_padded = pad_sequence(label_ids, batch_first=True, padding_value=-100)\n",
    "\n",
    "  return {\n",
    "      \"input_ids\": input_ids_padded,\n",
    "      \"attention_mask\": attention_mask_padded,\n",
    "      \"labels\": label_ids_padded\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hZ9oVX8XbK6W"
   },
   "outputs": [],
   "source": [
    "# ===== Simple Encoder =====\n",
    "class SimpleEncoder(nn.Module):\n",
    "  def __init__(self, vocab_size= vocab_size, hidden_dim=32):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "    self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "    x = self.embedding(input_ids)\n",
    "    x,_ = self.lstm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VaJvLhizcUiY"
   },
   "outputs": [],
   "source": [
    "# ===== TokenClassifier Model =====\n",
    "class TokenClassifier(nn.Module):\n",
    "  def __init__(self, encoder, num_labels):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.classifier = nn.Linear(encoder.lstm.hidden_size * 2, num_labels)\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "    x = self.encoder(input_ids)\n",
    "    logits = self.classifier(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2efbec441e3f4abe8581f25a1e44273f",
      "37b40bde72f34939a5f91e0156fcc77f",
      "6f861dd6df9344079c9f251ef6fd12d8",
      "664bcb33f2a241c3a2c2f2d7281783dd",
      "942cd29e93ad457296452dfbaa5d443a",
      "45737000a81a44cca3351b6eff796026",
      "e5c89d4e28304680885cf5b1c544425e",
      "99692ecdeb61436dbbd3c6924fd3e273",
      "0b3037deca164d889ba3d7390644df6a",
      "a68e8d53d82f4ef3850d50b557a15049",
      "41eb1d6aaf5b4f339a006b268ff67ca6"
     ]
    },
    "id": "r0p6TIiwdLi-",
    "outputId": "19e45881-caea-49e4-fbc8-180f15ea98be"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efbec441e3f4abe8581f25a1e44273f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Lightning Module =====\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "class NERModule(pl.LightningModule):\n",
    "  def __init__(self, model, lr=1e-3):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "    self.lr = lr\n",
    "    self.train_dataset = NERDataset(train_data, vocab_size) # Store dataset as an attribute\n",
    "    self.validation_dataset = NERDataset(validation_data, vocab_size)\n",
    "\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "      return self.model(input_ids)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.train_dataset, batch_size=3, shuffle=True, collate_fn=collate_fn) # Use collate_fn\n",
    "\n",
    "  def val_dataloader(self):\n",
    "      return DataLoader(self.validation_dataset, batch_size=3, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    # Unpack the tuple provided by the DataLoader with collate_fn\n",
    "    input_ids = batch['input_ids']\n",
    "    labels = batch['labels']\n",
    "\n",
    "    logits = self.model(input_ids)\n",
    "    loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self,batch, batch_idx):\n",
    "    input_ids = batch['input_ids']\n",
    "    labels = batch['labels']\n",
    "\n",
    "    logits = self.model(input_ids)\n",
    "    pred = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "    self.log(\"val_loss\", loss)\n",
    "\n",
    "    # Convert predictions and labels to lists for seqeval\n",
    "    predictions = []\n",
    "    references = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        preds_row = []\n",
    "        labels_row = []\n",
    "        for j in range(pred.shape[1]):\n",
    "            # Only include non-padded tokens (labels != -100)\n",
    "            if labels[i][j].item() != -100:\n",
    "                preds_row.append(id2label[str(pred[i][j].item())])\n",
    "                labels_row.append(id2label[str(labels[i][j].item())])\n",
    "        predictions.append(preds_row)\n",
    "        references.append(labels_row)\n",
    "\n",
    "    results = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # Log each metric individually\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            # Log nested metrics (precision, recall, f1, number)\n",
    "            for sub_key, sub_value in value.items():\n",
    "                self.log(f\"val_{key}_{sub_key}\", sub_value, prog_bar=True)\n",
    "        else:\n",
    "            # Log overall metrics (accuracy, f1, precision, recall)\n",
    "            self.log(f\"val_{key}\", value, prog_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644,
     "referenced_widgets": [
      "e4f91e70b1db4bd6995768dfec3f403e",
      "7ec8e24f767344c08a9a7ba85acab2a2",
      "0ded4c07c4964241ba9fa958b6d1689c",
      "1ac82b1164554d50b510643aa4119e24",
      "729aa19603084797abbbd3376cebba30",
      "b34dec7ebed843248ec289406dfe070d",
      "29fbcbfc48d847d484a53db9ef3b9bef",
      "844a6ef2fdbc450090358c7ba43bbdd5",
      "e89f0d51ff46465e95813863f3b6b058",
      "a05ec2d1191b44498088eef06c0b7b28",
      "a14a1310aed841aca9904aa4759ed8fd",
      "97f5ab172fbf4902ad6a2d8b7b1d86d6",
      "eff701df1451463a982df9685899a7fe",
      "0afe0ca317674a198dc975109a19df79",
      "c381ee25e4b046c58980cbf86ed91c4b",
      "cb4dcbf4fb6f4385a6ef94a25a7fb55a",
      "249961c91b6d40f682281f05961f217a",
      "6930df7028a74d4bb9b7bec5c54d3ec1",
      "3594b3cc51e640d29450e0f0ce4b2f6f",
      "5a4838e429314754b38ede009b8606ab",
      "e0fe6d626d78469e83b4f2b52fdba4b3",
      "db5767eefecd477db7bed8f1b3cd0cf3",
      "4681502ed3df4f1cb0f2079d18f705a6",
      "cd29843ddd69441d92845aefc1f7d537",
      "d3860a909d8641bd80b5ec7fc7d94610",
      "07d7a4024492478c9dd3ffde2b0c9e22",
      "6f95cecf9a8f45d580c3d2bf831353ed",
      "3254fb22a56046158e025563569fe1cc",
      "61e47a6c54a743b6b7ba1547ce3c41fc",
      "af05ea4a73f344f694a106045fbeb8f0",
      "467e1bc0ac6c40efb6a0928549e281b7",
      "0f0cc828964f4f98a769439e1ed41b0f",
      "ef5766ed9dfe46cc9c546dfc3aea9e20",
      "96e3af7378624336bf0b174a40553ef6",
      "a865cf2a067d4c4c93bb451574225966",
      "5c20d221d15748a18a8f27545d705229",
      "50a7d5df65254478940d1b5e599dd3c4",
      "4f8c3728550e4270854cd4b6ad131207",
      "db50cd050bc046b380198b15ad552a03",
      "d3bf9fa77dba4c1bad4d0b38b19b5c00",
      "9434d6b97b8b4bbcbe029b9ce7da57f7",
      "23d51573e1944502aed5b7b76b9990c2",
      "01d0b13115b64844956ebaeb7346c41f",
      "d566d89bff6c4245a8b3b9a9fac50cd3",
      "d79b4c5c8eb44eeba999e7ef63d6893d",
      "a1cf6d7660f0407db3deafe38e58fc41",
      "ea8cbd667e3a44edb08d88307e85d5a4",
      "1ad601bfdac741bfa15940137028f1c6",
      "544e60a5a3a0410bbe151812c581bef9",
      "c9d0413d96a44f858dcd8411e94a4a47",
      "4c85fda6dec2410e9bdd87c1a8ae2b87",
      "0f2033391ead4dd18b089951159e8053",
      "797f59fa776644b1b138fdf6e8dc6ec4",
      "6b17ffe588f0493eb31df3620d4266c0",
      "13fac0c6ce65467e9b404885c6875c7e",
      "f89c2a2372004fedbf4b96403e5186de",
      "7adde1bb0aff40e78f7650565f488941",
      "6455dbe6fbdf481eb55d7fd79514ea29",
      "a0d01c2738cb4068b8453aa884546d01",
      "9fa183ee34a3447ab6d44a1bc4272b9a",
      "60c9ce9bd22d4499978e00e617fadcab",
      "aa94324b602f461f962ef9395aaa49a7",
      "79fd9b9ad9214f10af5c56a63b0dd73f",
      "50d8a9ac2fd94c3bae4583891f56a1a0",
      "c0e4856b37e8481bb725bb7511227b07",
      "d5d9374c0cb0442283e35b85d76207e8",
      "94a1c9600a5c4bc1b3078d87d0a0e050",
      "b6cd61208f104c96b63bdbbd8a00d410",
      "9b17210e3d54435b9e8b0e2f99ae0867",
      "251862bdd3c94452b5e791b93b275dc4",
      "5e575ac8909d4cafae306862dfba1bc7",
      "d056390d7302479fb97c66211e5338b0",
      "481c77091c03443fb1cb23f5fa7a93ce",
      "b23edc61ae0c4dd3ab32ac76ed6b140e",
      "2756705080a04e3bb865d56f1e08fc5e",
      "206ba022422c4b70ad833f7352fcd3ee",
      "e8ebf330e228408188a88549ab9ff210",
      "4fefd73807ac40e89ac4e528f13aac80",
      "065d66c0f8f74d98af69b77cd6cdc4a4",
      "732fb2cc9ab94542a0fc40237b91e31b",
      "cb190759c3e2486fb602ef9c0b4a5c70",
      "acf8b88893bf4b6ba7cd206b456b5d47",
      "f2dcd14968f044f8a63a403f9ee8a0b1",
      "c460f1fa5d904ca9979be5dbf5b02b0b",
      "915feb92a3d04e6bab6b966a26da2a38",
      "d3a6af47dcfc48e3b67d09d6768d07af",
      "4efb33e1962241a68d75f17ca9ca1b31",
      "3d584235e29a4f4ba930aea61cc5ef82"
     ]
    },
    "id": "z_LTg9DEfqLQ",
    "outputId": "b0c042c8-60bc-41e6-e8b1-e658711ad7c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | TokenClassifier  | 994 K  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "994 K     Trainable params\n",
      "0         Non-trainable params\n",
      "994 K     Total params\n",
      "3.978     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f91e70b1db4bd6995768dfec3f403e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f5ab172fbf4902ad6a2d8b7b1d86d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4681502ed3df4f1cb0f2079d18f705a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/numpy/lib/_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e3af7378624336bf0b174a40553ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79b4c5c8eb44eeba999e7ef63d6893d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89c2a2372004fedbf4b96403e5186de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a1c9600a5c4bc1b3078d87d0a0e050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fefd73807ac40e89ac4e528f13aac80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    }
   ],
   "source": [
    "# ===== Training =====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_classes = 13\n",
    "\n",
    "encoder = SimpleEncoder(vocab_size=vocab_size)\n",
    "model = TokenClassifier(encoder, num_labels=num_classes)\n",
    "ner_module = NERModule(model)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=6, accelerator=device ,logger=False)\n",
    "trainer.fit(ner_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qdkmy7tH14Pa"
   },
   "source": [
    "##### **نتایج ارزیابی بالا در زیر تمیز نوشته شده**\n",
    "در فرم ژوپیتری کد نتایج مشخص نیستند.ولی نسخه دیگر را در کولب باز کنید نتایج کامل مشخص اند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3InuQ3a20azT",
    "outputId": "174f96c1-b171-41b3-896e-fa784e4b7528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 971},\n",
       " 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1110},\n",
       " 'group': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1110},\n",
       " 'location': {'precision': 0.022,\n",
       "  'recall': 0.0165,\n",
       "  'f1': 0.0183,\n",
       "  'number': 813},\n",
       " 'person': {'precision': 0.102, 'recall': 0.071, 'f1': 0.0803, 'number': 1780},\n",
       " 'product': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1300},\n",
       " 'overall_precision': 0.0818,\n",
       " 'overall_recall': 0.0417,\n",
       " 'overall_f1': 0.0527,\n",
       " 'overall_accuracy': 0.909}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  {\n",
    "    \"corporation\": {\n",
    "        \"precision\": 0.0,\n",
    "        \"recall\": 0.0,\n",
    "        \"f1\": 0.0,\n",
    "        \"number\": 971\n",
    "    },\n",
    "    \"creative-work\": {\n",
    "        \"precision\": 0.0,\n",
    "        \"recall\": 0.0,\n",
    "        \"f1\": 0.0,\n",
    "        \"number\": 1110\n",
    "    },\n",
    "    \"group\": {\n",
    "        \"precision\": 0.0,\n",
    "        \"recall\": 0.0,\n",
    "        \"f1\": 0.0,\n",
    "        \"number\": 1110\n",
    "    },\n",
    "    \"location\": {\n",
    "        \"precision\": 0.022,\n",
    "        \"recall\": 0.0165,\n",
    "        \"f1\": 0.0183,\n",
    "        \"number\": 813\n",
    "    },\n",
    "    \"person\": {\n",
    "        \"precision\": 0.102,\n",
    "        \"recall\": 0.071,\n",
    "        \"f1\": 0.0803,\n",
    "        \"number\": 1780\n",
    "    },\n",
    "    \"product\": {\n",
    "        \"precision\": 0.0,\n",
    "        \"recall\": 0.0,\n",
    "        \"f1\": 0.0,\n",
    "        \"number\": 1300\n",
    "    },\n",
    "    \"overall_precision\": 0.0818,\n",
    "    \"overall_recall\": 0.0417,\n",
    "    \"overall_f1\": 0.0527,\n",
    "    \"overall_accuracy\": 0.909\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDM5rZcGW_eV",
    "outputId": "6ad28ab8-0160-4505-ab32-f14bbd87ee6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"corporation\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1\": 0.0,\n",
      "        \"number\": 66\n",
      "    },\n",
      "    \"creative-work\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1\": 0.0,\n",
      "        \"number\": 142\n",
      "    },\n",
      "    \"group\": {\n",
      "        \"precision\": 0.16666666666666666,\n",
      "        \"recall\": 0.006060606060606061,\n",
      "        \"f1\": 0.011695906432748537,\n",
      "        \"number\": 165\n",
      "    },\n",
      "    \"location\": {\n",
      "        \"precision\": 0.08196721311475409,\n",
      "        \"recall\": 0.06666666666666667,\n",
      "        \"f1\": 0.07352941176470587,\n",
      "        \"number\": 150\n",
      "    },\n",
      "    \"person\": {\n",
      "        \"precision\": 0.1986754966887417,\n",
      "        \"recall\": 0.06993006993006994,\n",
      "        \"f1\": 0.10344827586206898,\n",
      "        \"number\": 429\n",
      "    },\n",
      "    \"product\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1\": 0.0,\n",
      "        \"number\": 127\n",
      "    },\n",
      "    \"overall_precision\": 0.13712374581939799,\n",
      "    \"overall_recall\": 0.037998146431881374,\n",
      "    \"overall_f1\": 0.059506531204644414,\n",
      "    \"overall_accuracy\": 0.9201402248728143\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ============ Test ============\n",
    "test_dataset = NERDataset(test_data, vocab_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=3, collate_fn=collate_fn)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "ner_module.eval()\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        logits = ner_module.model(input_ids)  # Explicitly call the model's forward\n",
    "        pred = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Convert predictions and labels to lists for seqeval\n",
    "        for i in range(pred.shape[0]):\n",
    "            preds_row = []\n",
    "            labels_row = []\n",
    "            for j in range(pred.shape[1]):\n",
    "                # Only include non-padded tokens (labels != -100)\n",
    "                if labels[i][j].item() != -100:\n",
    "                    preds_row.append(id2label[str(pred[i][j].item())])\n",
    "                    labels_row.append(id2label[str(labels[i][j].item())])\n",
    "            predictions.append(preds_row)\n",
    "            references.append(labels_row)\n",
    "\n",
    "\n",
    "# Compute metrics\n",
    "metric = load_metric(\"seqeval\")\n",
    "results = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Convert numpy/torch objects to standard Python types\n",
    "def convert_to_python_types(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_python_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_python_types(item) for item in obj]\n",
    "    elif isinstance(obj, (int, float, str, bool, type(None))):\n",
    "        return obj\n",
    "    elif isinstance(obj, (torch.Tensor)):\n",
    "        return obj.tolist()\n",
    "    elif hasattr(obj, 'item'): # Handle numpy scalars\n",
    "        return obj.item()\n",
    "    else:\n",
    "        return str(obj) # Convert other types to string\n",
    "\n",
    "results_python = convert_to_python_types(results)\n",
    "\n",
    "\n",
    "import json\n",
    "print(json.dumps(results_python, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49uht6bRxAV_"
   },
   "source": [
    "#### **📌 توضیح کلاس‌ها:**\n",
    "\n",
    "🟥**person** → اسم آدم‌ها (مثل: Elon Musk, Taylor Swift)\n",
    "\n",
    "🟪**location** → مکان‌ها (شهر، کشور، منطقه، آدرس؛ مثل: New York, Mount Everest)\n",
    "\n",
    "🟩**corporation** → شرکت‌ها و سازمان‌ها (مثل: Google, United Nations)\n",
    "\n",
    "🟨**product** → محصولات (مثل: iPhone 15, Coca-Cola)\n",
    "\n",
    "🟦**group** → گروه‌ها و تیم‌ها (مثل: The Beatles, Manchester United)\n",
    "\n",
    "🟧**creative-work** → آثار هنری یا رسانه‌ای (مثل: Harry Potter, Game of Thrones, Star Wars)\n",
    "\n",
    "\n",
    "این‌ها در واقع کلاس‌های موجودیت هستن که دیتاست تعریف کرده ⚡\n",
    "\n",
    " (یعنی هیچ موجودیتی نیست) می‌گیره  O یعنی هر توکنی که داخل متن هست، یا ⚡\n",
    "\n",
    " یا یکی از این برچسب‌ها\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "cells": [],
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "name": "python",
    "version": "3.10.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
