{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXdL4Q0OYiUm"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning  seqeval evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vrq_gmU8X1b7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import load_dataset\n",
    "from evaluate import load as load_metric\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "7c417de56e5441189f01c260445696b7",
      "be0f736616f34531888111884cafc125",
      "334f2a4922504c548e1a7b5711d1bc30",
      "91af6ee39590456ab3df885e5c6c13e5",
      "de74bf1096a146a4a24e8e8f72fa66ec",
      "48c0fdf1d73a455bb81b0c4ac5a9d9b9",
      "93823659faaf41f6a76e7bccb9e7a802",
      "83fbdadc91f7498cb4ea4036e6ee1484",
      "4dc0ca8ef4a94d69ac71d2ffdca492fb",
      "32cc826ccc914211b1adbebd5f361357",
      "759814104d6e4bd490839bd808705d40",
      "bf4d0f0e0166435db56659af3d4d19f6",
      "07398375eb6841de925c8673c303a81f",
      "d35fcce2194441348658b618c38ba2ba",
      "349a8ded89914bd98c6300cea93b989b",
      "4e6cfa33d03b4884ab62beb9551919ad",
      "1a6dcdcb5d6f419cba2810a646fbc8a1",
      "2f529fb69ffd40dfa9861b4393dee3cd",
      "ac7e4b3736484df991f1c44d7d1b3bc4",
      "0afe19d358dd4337a80042d57efd4f82",
      "6086a523ca2448219117fa7f1109c6d7",
      "b80088269c634b8c8e0a51bb333aac77",
      "b94d90ff68094d378cdbe9a8b64e8b12",
      "ed7aa98ae7254f82bb233ba6a6c57861",
      "c9c1b874ea974ffd90d7a893567aed62",
      "1fe2155021194237993c87f006f9f463",
      "00c909b88814494b8a926d9409c759d7",
      "32f93ffdbc4e47efa75736e015ba86b5",
      "423fc84b425e4ce689f2ed21d0c4c421",
      "e243c7e6632543ba9c3a7d075ec655fc",
      "a4462238481f42eab00937962e125c89",
      "43ad48a0c1084cb0b96f71f8cf376043",
      "d2837771921a47e2a1b009b9a7f8fd88",
      "6960d95d3c32483c8493d35502b41d61",
      "80ceadb833ba4da4ad7a8fcdc549b67f",
      "215f50849fac4a419c4aa5258611e1d7",
      "73b6544fa2bf4cf58810e55ca2a60598",
      "48a9b5a7fcc645c883b9051101ce874d",
      "c95b119d26974643a8994f5c8f94f50f",
      "cba10ad5fcac451992eaa369f818c2b2",
      "a190676817194d99af3e473981d62f72",
      "48914f3112bb484eba4248e98bf16087",
      "9020fd2a94ac4cb5af891a4d3f2a9a75",
      "826f139d90b742dcba4b5ab4e951900e",
      "18365d1d5295487a936382888ba66921",
      "e0d88230fc2141279f2af074d795ad5f",
      "d72709a4ac6b43058a5305a5b8474374",
      "5cf78f9af70848229e110e8ac5de5ab9",
      "885682e9ed164fda94ec0425ce95a2d6",
      "b7f76cda01cb4a8cbf5f4d7aa3fcfea1",
      "f2067053a06c455aba81ca569430a4bb",
      "3c83328e49694c75a845615295a97ee1",
      "511d88a35cb14596b7b760e5eeeedca3",
      "1e05734d910348c09fc2a7a340c2e21f",
      "d66dae0fa06946a29ba327400a41ec50",
      "326380d5f0ae4fbca6e9bee8e19c2df2",
      "2cc8d57e052445d9b5e716436ba68fb2",
      "c620ca645f614f18934d805509057311",
      "6492488fa31f4ac9b57af5100d44bc8d",
      "5abe708350324f1bbcee77376370ce06",
      "fb2519e272984f93bda72ccdebaf4fe6",
      "3ca8dff01652427fa002627632998a74",
      "11ab3e6e1e554bc68c2eadd8a0f1a71b",
      "781e1c5e755f4dd59eb3c11a8b75ad29",
      "321b93ba22a34cd58682696fcae96b42",
      "c19dbdedf39245829c630dbd70145402",
      "869178123a204e4696014f4e4134b176",
      "58d0521cbba043e3879ab6efb4e36b3a",
      "439092c6dfab477cb8f1e672e4a55fce",
      "6fd020f03daa41029882eb1fa26a2d37",
      "30c52fbf26e74ade9bcc5ced61070011",
      "15bb9f87e9b4498786cdc74027ad14f7",
      "dc5854f8d4cf4c00b4950cebae825b5e",
      "27969b1ce7ef460490732aa50293a578",
      "db73170ed709451daaec630a7e344113",
      "9d18d1d69aa646e38cb77368d820cc68",
      "66cf738b28b0436e96854682e46550a7"
     ]
    },
    "collapsed": true,
    "id": "IFxh5EsPCTXQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "af007187-7e71-4b1b-fc68-531efc531b53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c417de56e5441189f01c260445696b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/926 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4d0f0e0166435db56659af3d4d19f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/309k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94d90ff68094d378cdbe9a8b64e8b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001.parquet:   0%|          | 0.00/67.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6960d95d3c32483c8493d35502b41d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/116k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18365d1d5295487a936382888ba66921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326380d5f0ae4fbca6e9bee8e19c2df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869178123a204e4696014f4e4134b176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"manu/wnut_17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3I3A1O6C1-A",
    "outputId": "b5bac223-b054-452e-97af-10685034ca0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3394\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1009\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1287\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q68mC9oqEnIR"
   },
   "outputs": [],
   "source": [
    "# Dataset classes\n",
    "id2label ={'0': \"O\",\n",
    "            '1': \"B-corporation\",\n",
    "            '2': \"I-corporation\",\n",
    "            '3': \"B-creative-work\",\n",
    "            '4': \"I-creative-work\",\n",
    "            '5': \"B-group\",\n",
    "            '6': \"I-group\",\n",
    "            '7': \"B-location\",\n",
    "            '8': \"I-location\",\n",
    "            '9': \"B-person\",\n",
    "            '10': \"I-person\",\n",
    "            '11': \"B-product\",\n",
    "            '12': \"I-product\"}\n",
    "\n",
    "label2id = {k:v for v,k in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "e3174307d4ab442ea2ed6fa5fe2ff991",
      "e002da98454246b79e43ea062f060416",
      "6357ad44ee7247a0895ae9d28760a05d",
      "ca45477d003a49498f213e9de92890ff",
      "e3c098d3e7c84428ad51f3528f348acd",
      "cfba4312606e402fbde5748e3ecbd45b",
      "0df4df97e148407eb256c3835927f3ef",
      "29fc8965d1f34eb4b8da1f4693e58c1a",
      "5140bc4e3cd043ed93ec5221758b34dc",
      "625ad3d03c644d86915b51c088800bb6",
      "bef9da6021104bfda4c8635cc8cabdc0",
      "cbcab982156740c69efc4cf27378ea35",
      "603f5fa4c67a4fa69ff76348ed663e7e",
      "aaaaf89fc2e64c6b9209d7bb810a2987",
      "8d57bc9ad37b48d68a18f21192df718b",
      "be9e95d5108346fc9fe9149a5f891b25",
      "285fb1b5a40c4399870b383e47e380c8",
      "0eda35a9121c4ecf9c21129c63ee06ef",
      "495bf81d78e149ee8714c8aa54d7bb23",
      "c87a30edad7d44aea8a2307cfa28fdc4",
      "001be34da74142a08e1bf9540281d176",
      "fdedfdc1fc654668b45cea56d158807e",
      "234f318ad3364b17b935e6313ac2e16b",
      "d59947ed99c34e8b8b8330b9b38ff2e4",
      "b6c337b172854d0a8a31c6921a67ad69",
      "8aad184c6fc9418bbc55b2b6edc2d797",
      "67505496c62947509e9ce654dc452ff6",
      "8a38042d929c4795983f7c37470d3c3e",
      "c85d6e818db545c6a99ad4df3b2cd924",
      "86cfce1327994305b6e5bde3e2ce5d51",
      "c738f8df6c0c4f9cae94a3a08b63e106",
      "238b502715534bf2822443bae8afe628",
      "309c0001cd534b2d83c9e89d17903df0",
      "54d9aa57766444e1abc81b7ed3dbf273",
      "6bf40ac043ca47b389bff91d0d2be4b6",
      "61246ec48b954bdd9a07898bf0f946d0",
      "6261c743e5b846e8a956bc54768987af",
      "853b147edb9f40d6819dbd4039ed7bbb",
      "dca1cc2290da4f2d927ecd7beb56b9f6",
      "59806310c11b46a4b524d665f1b67960",
      "2991f4109f9d479687f8a7dd74399c2f",
      "d884dbaf3db0414aa37a336be39d0bbd",
      "fe6f6afc8e874523968f770645a56320",
      "c20908f6baaf4d7587c6176b9536a10a"
     ]
    },
    "collapsed": true,
    "id": "MJYcuoxAFPWu",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c2105e10-0278-4cce-8b88-fd746f939965"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3174307d4ab442ea2ed6fa5fe2ff991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcab982156740c69efc4cf27378ea35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234f318ad3364b17b935e6313ac2e16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d9aa57766444e1abc81b7ed3dbf273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2s6VkO1_NTa8"
   },
   "outputs": [],
   "source": [
    "def Preprocess_Dataset_2(dataset, split: str, tokenizer):\n",
    "    processed_data = []\n",
    "    for example in dataset[split]:\n",
    "        tokens = example['tokens']\n",
    "        ner_tags = example['ner_tags']\n",
    "\n",
    "        # Tokenize the entire sentence\n",
    "        tokenized_input = tokenizer(\n",
    "            tokens,\n",
    "            is_split_into_words=True,\n",
    "            padding=False,\n",
    "            truncation=False,\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "\n",
    "        word_ids = tokenized_input.word_ids()\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(ner_tags[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "\n",
    "        processed_data.append({\n",
    "            'input_ids': tokenized_input['input_ids'],\n",
    "            'attention_mask': tokenized_input['attention_mask'],\n",
    "            'labels': label_ids\n",
    "        })\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O5Fqo0rAIjWv"
   },
   "outputs": [],
   "source": [
    "train_data = Preprocess_Dataset_2(dataset,'train',tokenizer)\n",
    "validation_data = Preprocess_Dataset_2(dataset,'validation',tokenizer)\n",
    "test_data = Preprocess_Dataset_2(dataset,'test',tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "J0nWNXSuZwVf"
   },
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "  def __init__(self, data, tokenizer):\n",
    "    self.data = data\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return {\n",
    "\n",
    "            \"input_ids\": torch.tensor(self.data[idx]['input_ids']),\n",
    "            \"attention_mask\": torch.tensor(self.data[idx]['attention_mask']),\n",
    "            \"labels\": torch.tensor(self.data[idx]['labels'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "968RT7n_f5hS"
   },
   "source": [
    "**collate_fn**\n",
    "\n",
    "Ù…ØªØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù‡Ù…Ù‡ Ù‡Ù… Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø§Ø´Ù†Ø¯\n",
    "\n",
    "ÛŒÚ© Ø¨Ú† Ø§Ø² Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ Ø±Ø§ Ù…ÛŒÚ¯Ø±Ø¯ Ùˆ Ù‡Ù…Ù‡ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ Ø¢Ù† Ø¨Ú† Ø±Ø§ Ù¾Ø¯ Ù…ÛŒÚ©Ù†Ø¯\n",
    "\n",
    "Ø§ÛŒÙ† Ù…ØªØ¯ Ø¯Ø± Ø¯ÛŒØªØ§Ù„ÙˆØ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒØ´Ù‡\n",
    "\n",
    "Ø¯Ø± ÙˆØ§Ù‚Ø¹ **Ù‡Ø± Ø¨Ø§Ø± Ú©Ù‡ Ø¯ÛŒØªØ§Ù„ÙˆØ¯Ø± ÛŒÚ© Ø¨Ú† Ø¨Ø±Ù…ÛŒÚ¯Ø±Ø¯ÙˆÙ†Ù‡ Ø§ÛŒÙ† Ù…ØªØ¯ Ø±ÙˆÛŒ Ø§ÙˆÙ† Ø¨Ú† Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒØ´Ù‡**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AW61SrZLks7i"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  input_ids, attention_mask, label_ids = zip(*[(item['input_ids'], item['attention_mask'], item['labels']) for item in batch])\n",
    "\n",
    "  input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "  attention_mask_padded = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "  label_ids_padded = pad_sequence(label_ids, batch_first=True, padding_value=-100)\n",
    "\n",
    "  return {\n",
    "      \"input_ids\": input_ids_padded,\n",
    "      \"attention_mask\": attention_mask_padded,\n",
    "      \"labels\": label_ids_padded\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibunl12YEvgT"
   },
   "source": [
    "Encoder-Architecture :\n",
    "\n",
    "Embedding âŸ¶ LSTM âŸ¶ Dropout âŸ¶ Projection(Linear-Layer) âŸ¶ Skip-Connection âŸ¶ LayerNorm âŸ¶ Conv1D(kenelr-size=3) âŸ¶ LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "hZ9oVX8XbK6W"
   },
   "outputs": [],
   "source": [
    "# ===== Simple Encoder =====\n",
    "class SimpleEncoder(nn.Module):\n",
    "  def __init__(self, vocab_size= vocab_size, hidden_dim=32):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "    self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "    # Add a linear layer to project the LSTM output to the embedding dimension\n",
    "    self.lstm_projection = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "    # Add a Conv1D layer\n",
    "    self.conv1d = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding='same') # Ensure padding is 'same' for matching dimensions\n",
    "    self.dropout = nn.Dropout(0.3)\n",
    "    self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "    self.ln2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "    x = self.embedding(input_ids)\n",
    "    y,_ = self.lstm(x)  # ouput_dim(y) = 64  & input_dim(x) = 32\n",
    "    y = self.dropout(y)\n",
    "    # Project the LSTM output before adding\n",
    "    y_projected = self.lstm_projection(y)  # reduce output_dim(y) (64 --> 32)\n",
    "\n",
    "    x = x+y_projected  # skip-connection\n",
    "    x = self.ln1(x)\n",
    "\n",
    "    x = x.permute(0, 2, 1)\n",
    "    x = self.conv1d(x)\n",
    "    x = x.permute(0, 2, 1) # Permute back\n",
    "\n",
    "    x = self.ln2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "VaJvLhizcUiY"
   },
   "outputs": [],
   "source": [
    "# ===== TokenClassifier Model =====\n",
    "class TokenClassifier(nn.Module):\n",
    "  def __init__(self, encoder, num_labels):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    # The classifier input size should be the projected dimension from the encoder\n",
    "    self.classifier = nn.Linear(encoder.lstm_projection.out_features, num_labels)\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "    x = self.encoder(input_ids)\n",
    "    logits = self.classifier(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "r0p6TIiwdLi-"
   },
   "outputs": [],
   "source": [
    "# ===== Lightning Module =====\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "class NERModule(pl.LightningModule):\n",
    "  def __init__(self, model, lr=1e-3):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "    self.lr = lr\n",
    "    self.train_dataset = NERDataset(train_data, vocab_size) # Store dataset as an attribute\n",
    "    self.validation_dataset = NERDataset(validation_data, vocab_size)\n",
    "\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "      return self.model(input_ids)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.train_dataset, batch_size=3, shuffle=True, collate_fn=collate_fn) # Use collate_fn\n",
    "\n",
    "  def val_dataloader(self):\n",
    "      return DataLoader(self.validation_dataset, batch_size=3, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    # Unpack the tuple provided by the DataLoader with collate_fn\n",
    "    input_ids = batch['input_ids']\n",
    "    labels = batch['labels']\n",
    "\n",
    "    logits = self.model(input_ids)\n",
    "    loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self,batch, batch_idx):\n",
    "    input_ids = batch['input_ids']\n",
    "    labels = batch['labels']\n",
    "\n",
    "    logits = self.model(input_ids)\n",
    "    pred = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "    self.log(\"val_loss\", loss)\n",
    "\n",
    "    # Convert predictions and labels to lists for seqeval\n",
    "    predictions = []\n",
    "    references = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        preds_row = []\n",
    "        labels_row = []\n",
    "        for j in range(pred.shape[1]):\n",
    "            # Only include non-padded tokens (labels != -100)\n",
    "            if labels[i][j].item() != -100:\n",
    "                preds_row.append(id2label[str(pred[i][j].item())])\n",
    "                labels_row.append(id2label[str(labels[i][j].item())])\n",
    "        predictions.append(preds_row)\n",
    "        references.append(labels_row)\n",
    "\n",
    "    results = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # Log each metric individually\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            # Log nested metrics (precision, recall, f1, number)\n",
    "            for sub_key, sub_value in value.items():\n",
    "                self.log(f\"val_{key}_{sub_key}\", sub_value, prog_bar=True)\n",
    "        else:\n",
    "            # Log overall metrics (accuracy, f1, precision, recall)\n",
    "            self.log(f\"val_{key}\", value, prog_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_LTg9DEfqLQ"
   },
   "outputs": [],
   "source": [
    "# ===== Training =====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_classes = 13\n",
    "\n",
    "encoder = SimpleEncoder(vocab_size=vocab_size)\n",
    "model = TokenClassifier(encoder, num_labels=num_classes)\n",
    "ner_module = NERModule(model)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator=device ,logger=False)\n",
    "trainer.fit(ner_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDM5rZcGW_eV",
    "outputId": "3eb19168-1e54-4d4e-96e1-a08037ad9764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"corporation\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1\": 0.0,\n",
      "        \"number\": 66\n",
      "    },\n",
      "    \"creative-work\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1\": 0.0,\n",
      "        \"number\": 142\n",
      "    },\n",
      "    \"group\": {\n",
      "        \"precision\": 0.0625,\n",
      "        \"recall\": 0.006060606060606061,\n",
      "        \"f1\": 0.011049723756906079,\n",
      "        \"number\": 165\n",
      "    },\n",
      "    \"location\": {\n",
      "        \"precision\": 0.10714285714285714,\n",
      "        \"recall\": 0.08,\n",
      "        \"f1\": 0.0916030534351145,\n",
      "        \"number\": 150\n",
      "    },\n",
      "    \"person\": {\n",
      "        \"precision\": 0.14685314685314685,\n",
      "        \"recall\": 0.04895104895104895,\n",
      "        \"f1\": 0.07342657342657342,\n",
      "        \"number\": 429\n",
      "    },\n",
      "    \"product\": {\n",
      "        \"precision\": 0.08333333333333333,\n",
      "        \"recall\": 0.007874015748031496,\n",
      "        \"f1\": 0.014388489208633094,\n",
      "        \"number\": 127\n",
      "    },\n",
      "    \"overall_precision\": 0.1174496644295302,\n",
      "    \"overall_recall\": 0.03243744207599629,\n",
      "    \"overall_f1\": 0.05083514887436455,\n",
      "    \"overall_accuracy\": 0.9203539823008849\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ============ Test ============\n",
    "test_dataset = NERDataset(test_data, vocab_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=3, collate_fn=collate_fn)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "ner_module.eval()\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        logits = ner_module.model(input_ids)  # Explicitly call the model's forward\n",
    "        pred = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Convert predictions and labels to lists for seqeval\n",
    "        for i in range(pred.shape[0]):\n",
    "            preds_row = []\n",
    "            labels_row = []\n",
    "            for j in range(pred.shape[1]):\n",
    "                # Only include non-padded tokens (labels != -100)\n",
    "                if labels[i][j].item() != -100:\n",
    "                    preds_row.append(id2label[str(pred[i][j].item())])\n",
    "                    labels_row.append(id2label[str(labels[i][j].item())])\n",
    "            predictions.append(preds_row)\n",
    "            references.append(labels_row)\n",
    "\n",
    "\n",
    "# Compute metrics\n",
    "metric = load_metric(\"seqeval\")\n",
    "results = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Convert numpy/torch objects to standard Python types\n",
    "def convert_to_python_types(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_python_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_python_types(item) for item in obj]\n",
    "    elif isinstance(obj, (int, float, str, bool, type(None))):\n",
    "        return obj\n",
    "    elif isinstance(obj, (torch.Tensor)):\n",
    "        return obj.tolist()\n",
    "    elif hasattr(obj, 'item'): # Handle numpy scalars\n",
    "        return obj.item()\n",
    "    else:\n",
    "        return str(obj) # Convert other types to string\n",
    "\n",
    "results_python = convert_to_python_types(results)\n",
    "\n",
    "\n",
    "import json\n",
    "print(json.dumps(results_python, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49uht6bRxAV_"
   },
   "source": [
    "#### **ğŸ“Œ ØªÙˆØ¶ÛŒØ­ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§:**\n",
    "\n",
    "ğŸŸ¥**person** â†’ Ø§Ø³Ù… Ø¢Ø¯Ù…â€ŒÙ‡Ø§ (Ù…Ø«Ù„: Elon Musk, Taylor Swift)\n",
    "\n",
    "ğŸŸª**location** â†’ Ù…Ú©Ø§Ù†â€ŒÙ‡Ø§ (Ø´Ù‡Ø±ØŒ Ú©Ø´ÙˆØ±ØŒ Ù…Ù†Ø·Ù‚Ù‡ØŒ Ø¢Ø¯Ø±Ø³Ø› Ù…Ø«Ù„: New York, Mount Everest)\n",
    "\n",
    "ğŸŸ©**corporation** â†’ Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§ Ùˆ Ø³Ø§Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ (Ù…Ø«Ù„: Google, United Nations)\n",
    "\n",
    "ğŸŸ¨**product** â†’ Ù…Ø­ØµÙˆÙ„Ø§Øª (Ù…Ø«Ù„: iPhone 15, Coca-Cola)\n",
    "\n",
    "ğŸŸ¦**group** â†’ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ Ùˆ ØªÛŒÙ…â€ŒÙ‡Ø§ (Ù…Ø«Ù„: The Beatles, Manchester United)\n",
    "\n",
    "ğŸŸ§**creative-work** â†’ Ø¢Ø«Ø§Ø± Ù‡Ù†Ø±ÛŒ ÛŒØ§ Ø±Ø³Ø§Ù†Ù‡â€ŒØ§ÛŒ (Ù…Ø«Ù„: Harry Potter, Game of Thrones, Star Wars)\n",
    "\n",
    "\n",
    "Ø§ÛŒÙ†â€ŒÙ‡Ø§ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØª Ù‡Ø³ØªÙ† Ú©Ù‡ Ø¯ÛŒØªØ§Ø³Øª ØªØ¹Ø±ÛŒÙ Ú©Ø±Ø¯Ù‡ âš¡\n",
    "\n",
    " (ÛŒØ¹Ù†ÛŒ Ù‡ÛŒÚ† Ù…ÙˆØ¬ÙˆØ¯ÛŒØªÛŒ Ù†ÛŒØ³Øª) Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù‡  O ÛŒØ¹Ù†ÛŒ Ù‡Ø± ØªÙˆÚ©Ù†ÛŒ Ú©Ù‡ Ø¯Ø§Ø®Ù„ Ù…ØªÙ† Ù‡Ø³ØªØŒ ÛŒØ§ âš¡\n",
    "\n",
    " ÛŒØ§ ÛŒÚ©ÛŒ Ø§Ø² Ø§ÛŒÙ† Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "cells": [],
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "name": "python",
    "version": "3.10.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
