{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXdL4Q0OYiUm"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning  seqeval evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vrq_gmU8X1b7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import load_dataset\n",
    "from evaluate import load as load_metric\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "7c417de56e5441189f01c260445696b7",
      "be0f736616f34531888111884cafc125",
      "334f2a4922504c548e1a7b5711d1bc30",
      "91af6ee39590456ab3df885e5c6c13e5",
      "de74bf1096a146a4a24e8e8f72fa66ec",
      "48c0fdf1d73a455bb81b0c4ac5a9d9b9",
      "93823659faaf41f6a76e7bccb9e7a802",
      "83fbdadc91f7498cb4ea4036e6ee1484",
      "4dc0ca8ef4a94d69ac71d2ffdca492fb",
      "32cc826ccc914211b1adbebd5f361357",
      "759814104d6e4bd490839bd808705d40",
      "bf4d0f0e0166435db56659af3d4d19f6",
      "07398375eb6841de925c8673c303a81f",
      "d35fcce2194441348658b618c38ba2ba",
      "349a8ded89914bd98c6300cea93b989b",
      "4e6cfa33d03b4884ab62beb9551919ad",
      "1a6dcdcb5d6f419cba2810a646fbc8a1",
      "2f529fb69ffd40dfa9861b4393dee3cd",
      "ac7e4b3736484df991f1c44d7d1b3bc4",
      "0afe19d358dd4337a80042d57efd4f82",
      "6086a523ca2448219117fa7f1109c6d7",
      "b80088269c634b8c8e0a51bb333aac77",
      "b94d90ff68094d378cdbe9a8b64e8b12",
      "ed7aa98ae7254f82bb233ba6a6c57861",
      "c9c1b874ea974ffd90d7a893567aed62",
      "1fe2155021194237993c87f006f9f463",
      "00c909b88814494b8a926d9409c759d7",
      "32f93ffdbc4e47efa75736e015ba86b5",
      "423fc84b425e4ce689f2ed21d0c4c421",
      "e243c7e6632543ba9c3a7d075ec655fc",
      "a4462238481f42eab00937962e125c89",
      "43ad48a0c1084cb0b96f71f8cf376043",
      "d2837771921a47e2a1b009b9a7f8fd88",
      "6960d95d3c32483c8493d35502b41d61",
      "80ceadb833ba4da4ad7a8fcdc549b67f",
      "215f50849fac4a419c4aa5258611e1d7",
      "73b6544fa2bf4cf58810e55ca2a60598",
      "48a9b5a7fcc645c883b9051101ce874d",
      "c95b119d26974643a8994f5c8f94f50f",
      "cba10ad5fcac451992eaa369f818c2b2",
      "a190676817194d99af3e473981d62f72",
      "48914f3112bb484eba4248e98bf16087",
      "9020fd2a94ac4cb5af891a4d3f2a9a75",
      "826f139d90b742dcba4b5ab4e951900e",
      "18365d1d5295487a936382888ba66921",
      "e0d88230fc2141279f2af074d795ad5f",
      "d72709a4ac6b43058a5305a5b8474374",
      "5cf78f9af70848229e110e8ac5de5ab9",
      "885682e9ed164fda94ec0425ce95a2d6",
      "b7f76cda01cb4a8cbf5f4d7aa3fcfea1",
      "f2067053a06c455aba81ca569430a4bb",
      "3c83328e49694c75a845615295a97ee1",
      "511d88a35cb14596b7b760e5eeeedca3",
      "1e05734d910348c09fc2a7a340c2e21f",
      "d66dae0fa06946a29ba327400a41ec50",
      "326380d5f0ae4fbca6e9bee8e19c2df2",
      "2cc8d57e052445d9b5e716436ba68fb2",
      "c620ca645f614f18934d805509057311",
      "6492488fa31f4ac9b57af5100d44bc8d",
      "5abe708350324f1bbcee77376370ce06",
      "fb2519e272984f93bda72ccdebaf4fe6",
      "3ca8dff01652427fa002627632998a74",
      "11ab3e6e1e554bc68c2eadd8a0f1a71b",
      "781e1c5e755f4dd59eb3c11a8b75ad29",
      "321b93ba22a34cd58682696fcae96b42",
      "c19dbdedf39245829c630dbd70145402",
      "869178123a204e4696014f4e4134b176",
      "58d0521cbba043e3879ab6efb4e36b3a",
      "439092c6dfab477cb8f1e672e4a55fce",
      "6fd020f03daa41029882eb1fa26a2d37",
      "30c52fbf26e74ade9bcc5ced61070011",
      "15bb9f87e9b4498786cdc74027ad14f7",
      "dc5854f8d4cf4c00b4950cebae825b5e",
      "27969b1ce7ef460490732aa50293a578",
      "db73170ed709451daaec630a7e344113",
      "9d18d1d69aa646e38cb77368d820cc68",
      "66cf738b28b0436e96854682e46550a7"
     ]
    },
    "collapsed": true,
    "id": "IFxh5EsPCTXQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "af007187-7e71-4b1b-fc68-531efc531b53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c417de56e5441189f01c260445696b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/926 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4d0f0e0166435db56659af3d4d19f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/309k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94d90ff68094d378cdbe9a8b64e8b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001.parquet:   0%|          | 0.00/67.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6960d95d3c32483c8493d35502b41d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/116k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18365d1d5295487a936382888ba66921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326380d5f0ae4fbca6e9bee8e19c2df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869178123a204e4696014f4e4134b176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"manu/wnut_17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3I3A1O6C1-A",
    "outputId": "b5bac223-b054-452e-97af-10685034ca0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3394\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1009\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1287\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q68mC9oqEnIR"
   },
   "outputs": [],
   "source": [
    "# Dataset classes\n",
    "id2label ={'0': \"O\",\n",
    "            '1': \"B-corporation\",\n",
    "            '2': \"I-corporation\",\n",
    "            '3': \"B-creative-work\",\n",
    "            '4': \"I-creative-work\",\n",
    "            '5': \"B-group\",\n",
    "            '6': \"I-group\",\n",
    "            '7': \"B-location\",\n",
    "            '8': \"I-location\",\n",
    "            '9': \"B-person\",\n",
    "            '10': \"I-person\",\n",
    "            '11': \"B-product\",\n",
    "            '12': \"I-product\"}\n",
    "\n",
    "label2id = {k:v for v,k in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "e3174307d4ab442ea2ed6fa5fe2ff991",
      "e002da98454246b79e43ea062f060416",
      "6357ad44ee7247a0895ae9d28760a05d",
      "ca45477d003a49498f213e9de92890ff",
      "e3c098d3e7c84428ad51f3528f348acd",
      "cfba4312606e402fbde5748e3ecbd45b",
      "0df4df97e148407eb256c3835927f3ef",
      "29fc8965d1f34eb4b8da1f4693e58c1a",
      "5140bc4e3cd043ed93ec5221758b34dc",
      "625ad3d03c644d86915b51c088800bb6",
      "bef9da6021104bfda4c8635cc8cabdc0",
      "cbcab982156740c69efc4cf27378ea35",
      "603f5fa4c67a4fa69ff76348ed663e7e",
      "aaaaf89fc2e64c6b9209d7bb810a2987",
      "8d57bc9ad37b48d68a18f21192df718b",
      "be9e95d5108346fc9fe9149a5f891b25",
      "285fb1b5a40c4399870b383e47e380c8",
      "0eda35a9121c4ecf9c21129c63ee06ef",
      "495bf81d78e149ee8714c8aa54d7bb23",
      "c87a30edad7d44aea8a2307cfa28fdc4",
      "001be34da74142a08e1bf9540281d176",
      "fdedfdc1fc654668b45cea56d158807e",
      "234f318ad3364b17b935e6313ac2e16b",
      "d59947ed99c34e8b8b8330b9b38ff2e4",
      "b6c337b172854d0a8a31c6921a67ad69",
      "8aad184c6fc9418bbc55b2b6edc2d797",
      "67505496c62947509e9ce654dc452ff6",
      "8a38042d929c4795983f7c37470d3c3e",
      "c85d6e818db545c6a99ad4df3b2cd924",
      "86cfce1327994305b6e5bde3e2ce5d51",
      "c738f8df6c0c4f9cae94a3a08b63e106",
      "238b502715534bf2822443bae8afe628",
      "309c0001cd534b2d83c9e89d17903df0",
      "54d9aa57766444e1abc81b7ed3dbf273",
      "6bf40ac043ca47b389bff91d0d2be4b6",
      "61246ec48b954bdd9a07898bf0f946d0",
      "6261c743e5b846e8a956bc54768987af",
      "853b147edb9f40d6819dbd4039ed7bbb",
      "dca1cc2290da4f2d927ecd7beb56b9f6",
      "59806310c11b46a4b524d665f1b67960",
      "2991f4109f9d479687f8a7dd74399c2f",
      "d884dbaf3db0414aa37a336be39d0bbd",
      "fe6f6afc8e874523968f770645a56320",
      "c20908f6baaf4d7587c6176b9536a10a"
     ]
    },
    "collapsed": true,
    "id": "MJYcuoxAFPWu",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c2105e10-0278-4cce-8b88-fd746f939965"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3174307d4ab442ea2ed6fa5fe2ff991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcab982156740c69efc4cf27378ea35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234f318ad3364b17b935e6313ac2e16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d9aa57766444e1abc81b7ed3dbf273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2s6VkO1_NTa8"
   },
   "outputs": [],
   "source": [
    "def Preprocess_Dataset_2(dataset, split: str, tokenizer):\n",
    "    processed_data = []\n",
    "    for example in dataset[split]:\n",
    "        tokens = example['tokens']\n",
    "        ner_tags = example['ner_tags']\n",
    "\n",
    "        # Tokenize the entire sentence\n",
    "        tokenized_input = tokenizer(\n",
    "            tokens,\n",
    "            is_split_into_words=True,\n",
    "            padding=False,\n",
    "            truncation=False,\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "\n",
    "        word_ids = tokenized_input.word_ids()\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(ner_tags[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "\n",
    "        processed_data.append({\n",
    "            'input_ids': tokenized_input['input_ids'],\n",
    "            'attention_mask': tokenized_input['attention_mask'],\n",
    "            'labels': label_ids\n",
    "        })\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O5Fqo0rAIjWv"
   },
   "outputs": [],
   "source": [
    "train_data = Preprocess_Dataset_2(dataset,'train',tokenizer)\n",
    "validation_data = Preprocess_Dataset_2(dataset,'validation',tokenizer)\n",
    "test_data = Preprocess_Dataset_2(dataset,'test',tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "J0nWNXSuZwVf"
   },
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "  def __init__(self, data, tokenizer):\n",
    "    self.data = data\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return {\n",
    "\n",
    "            \"input_ids\": torch.tensor(self.data[idx]['input_ids']),\n",
    "            \"attention_mask\": torch.tensor(self.data[idx]['attention_mask']),\n",
    "            \"labels\": torch.tensor(self.data[idx]['labels'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "968RT7n_f5hS"
   },
   "source": [
    "**collate_fn**\n",
    "\n",
    "متدی برای پد کردن داده ها برای اینکه همه هم اندازه باشند\n",
    "\n",
    "یک بچ از داده ها را میگرد و همه داده های آن بچ را پد میکند\n",
    "\n",
    "این متد در دیتالودر استفاده میشه\n",
    "\n",
    "در واقع **هر بار که دیتالودر یک بچ برمیگردونه این متد روی اون بچ اعمال میشه**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AW61SrZLks7i"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  input_ids, attention_mask, label_ids = zip(*[(item['input_ids'], item['attention_mask'], item['labels']) for item in batch])\n",
    "\n",
    "  input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "  attention_mask_padded = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "  label_ids_padded = pad_sequence(label_ids, batch_first=True, padding_value=-100)\n",
    "\n",
    "  return {\n",
    "      \"input_ids\": input_ids_padded,\n",
    "      \"attention_mask\": attention_mask_padded,\n",
    "      \"labels\": label_ids_padded\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibunl12YEvgT"
   },
   "source": [
    "Encoder-Architecture :\n",
    "\n",
    "Embedding ⟶ LSTM ⟶ Dropout ⟶ Projection(Linear-Layer) ⟶ Skip-Connection ⟶ LayerNorm ⟶ Conv1D(kenelr-size=3) ⟶ LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "hZ9oVX8XbK6W"
   },
   "outputs": [],
   "source": [
    "# ===== Simple Encoder =====\n",
    "class SimpleEncoder(nn.Module):\n",
    "  def __init__(self, vocab_size= vocab_size, hidden_dim=32):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "    self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "    # Add a linear layer to project the LSTM output to the embedding dimension\n",
    "    self.lstm_projection = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "    # Add a Conv1D layer\n",
    "    self.conv1d = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding='same') # Ensure padding is 'same' for matching dimensions\n",
    "    self.dropout = nn.Dropout(0.3)\n",
    "    self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "    self.ln2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "    x = self.embedding(input_ids)\n",
    "    y,_ = self.lstm(x)  # ouput_dim(y) = 64  & input_dim(x) = 32\n",
    "    y = self.dropout(y)\n",
    "    # Project the LSTM output before adding\n",
    "    y_projected = self.lstm_projection(y)  # reduce output_dim(y) (64 --> 32)\n",
    "\n",
    "    x = x+y_projected  # skip-connection\n",
    "    x = self.ln1(x)\n",
    "\n",
    "    x = x.permute(0, 2, 1)\n",
    "    x = self.conv1d(x)\n",
    "    x = x.permute(0, 2, 1) # Permute back\n",
    "\n",
    "    x = self.ln2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "VaJvLhizcUiY"
   },
   "outputs": [],
   "source": [
    "# ===== TokenClassifier Model =====\n",
    "class TokenClassifier(nn.Module):\n",
    "  def __init__(self, encoder, num_labels):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    # The classifier input size should be the projected dimension from the encoder\n",
    "    self.classifier = nn.Linear(encoder.lstm_projection.out_features, num_labels)\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "    x = self.encoder(input_ids)\n",
    "    logits = self.classifier(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "r0p6TIiwdLi-"
   },
   "outputs": [],
   "source": [
    "# ===== Lightning Module =====\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "class NERModule(pl.LightningModule):\n",
    "  def __init__(self, model, lr=1e-3):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "    self.lr = lr\n",
    "    self.train_dataset = NERDataset(train_data, vocab_size) # Store dataset as an attribute\n",
    "    self.validation_dataset = NERDataset(validation_data, vocab_size)\n",
    "\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "      return self.model(input_ids)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.train_dataset, batch_size=3, shuffle=True, collate_fn=collate_fn) # Use collate_fn\n",
    "\n",
    "  def val_dataloader(self):\n",
    "      return DataLoader(self.validation_dataset, batch_size=3, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    # Unpack the tuple provided by the DataLoader with collate_fn\n",
    "    input_ids = batch['input_ids']\n",
    "    labels = batch['labels']\n",
    "\n",
    "    logits = self.model(input_ids)\n",
    "    loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self,batch, batch_idx):\n",
    "    input_ids = batch['input_ids']\n",
    "    labels = batch['labels']\n",
    "\n",
    "    logits = self.model(input_ids)\n",
    "    pred = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "    self.log(\"val_loss\", loss)\n",
    "\n",
    "    # Convert predictions and labels to lists for seqeval\n",
    "    predictions = []\n",
    "    references = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        preds_row = []\n",
    "        labels_row = []\n",
    "        for j in range(pred.shape[1]):\n",
    "            # Only include non-padded tokens (labels != -100)\n",
    "            if labels[i][j].item() != -100:\n",
    "                preds_row.append(id2label[str(pred[i][j].item())])\n",
    "                labels_row.append(id2label[str(labels[i][j].item())])\n",
    "        predictions.append(preds_row)\n",
    "        references.append(labels_row)\n",
    "\n",
    "    results = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # Log each metric individually\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            # Log nested metrics (precision, recall, f1, number)\n",
    "            for sub_key, sub_value in value.items():\n",
    "                self.log(f\"val_{key}_{sub_key}\", sub_value, prog_bar=True)\n",
    "        else:\n",
    "            # Log overall metrics (accuracy, f1, precision, recall)\n",
    "            self.log(f\"val_{key}\", value, prog_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_LTg9DEfqLQ"
   },
   "outputs": [],
   "source": [
    "# ===== Training =====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_classes = 13\n",
    "\n",
    "encoder = SimpleEncoder(vocab_size=vocab_size)\n",
    "model = TokenClassifier(encoder, num_labels=num_classes)\n",
    "ner_module = NERModule(model)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator=device ,logger=False)\n",
    "trainer.fit(ner_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDM5rZcGW_eV",
    "outputId": "3eb19168-1e54-4d4e-96e1-a08037ad9764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"corporation\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1\": 0.0,\n",
      "        \"number\": 66\n",
      "    },\n",
      "    \"creative-work\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1\": 0.0,\n",
      "        \"number\": 142\n",
      "    },\n",
      "    \"group\": {\n",
      "        \"precision\": 0.0625,\n",
      "        \"recall\": 0.006060606060606061,\n",
      "        \"f1\": 0.011049723756906079,\n",
      "        \"number\": 165\n",
      "    },\n",
      "    \"location\": {\n",
      "        \"precision\": 0.10714285714285714,\n",
      "        \"recall\": 0.08,\n",
      "        \"f1\": 0.0916030534351145,\n",
      "        \"number\": 150\n",
      "    },\n",
      "    \"person\": {\n",
      "        \"precision\": 0.14685314685314685,\n",
      "        \"recall\": 0.04895104895104895,\n",
      "        \"f1\": 0.07342657342657342,\n",
      "        \"number\": 429\n",
      "    },\n",
      "    \"product\": {\n",
      "        \"precision\": 0.08333333333333333,\n",
      "        \"recall\": 0.007874015748031496,\n",
      "        \"f1\": 0.014388489208633094,\n",
      "        \"number\": 127\n",
      "    },\n",
      "    \"overall_precision\": 0.1174496644295302,\n",
      "    \"overall_recall\": 0.03243744207599629,\n",
      "    \"overall_f1\": 0.05083514887436455,\n",
      "    \"overall_accuracy\": 0.9203539823008849\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ============ Test ============\n",
    "test_dataset = NERDataset(test_data, vocab_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=3, collate_fn=collate_fn)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "ner_module.eval()\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        logits = ner_module.model(input_ids)  # Explicitly call the model's forward\n",
    "        pred = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Convert predictions and labels to lists for seqeval\n",
    "        for i in range(pred.shape[0]):\n",
    "            preds_row = []\n",
    "            labels_row = []\n",
    "            for j in range(pred.shape[1]):\n",
    "                # Only include non-padded tokens (labels != -100)\n",
    "                if labels[i][j].item() != -100:\n",
    "                    preds_row.append(id2label[str(pred[i][j].item())])\n",
    "                    labels_row.append(id2label[str(labels[i][j].item())])\n",
    "            predictions.append(preds_row)\n",
    "            references.append(labels_row)\n",
    "\n",
    "\n",
    "# Compute metrics\n",
    "metric = load_metric(\"seqeval\")\n",
    "results = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Convert numpy/torch objects to standard Python types\n",
    "def convert_to_python_types(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_python_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_python_types(item) for item in obj]\n",
    "    elif isinstance(obj, (int, float, str, bool, type(None))):\n",
    "        return obj\n",
    "    elif isinstance(obj, (torch.Tensor)):\n",
    "        return obj.tolist()\n",
    "    elif hasattr(obj, 'item'): # Handle numpy scalars\n",
    "        return obj.item()\n",
    "    else:\n",
    "        return str(obj) # Convert other types to string\n",
    "\n",
    "results_python = convert_to_python_types(results)\n",
    "\n",
    "\n",
    "import json\n",
    "print(json.dumps(results_python, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49uht6bRxAV_"
   },
   "source": [
    "#### **📌 توضیح کلاس‌ها:**\n",
    "\n",
    "🟥**person** → اسم آدم‌ها (مثل: Elon Musk, Taylor Swift)\n",
    "\n",
    "🟪**location** → مکان‌ها (شهر، کشور، منطقه، آدرس؛ مثل: New York, Mount Everest)\n",
    "\n",
    "🟩**corporation** → شرکت‌ها و سازمان‌ها (مثل: Google, United Nations)\n",
    "\n",
    "🟨**product** → محصولات (مثل: iPhone 15, Coca-Cola)\n",
    "\n",
    "🟦**group** → گروه‌ها و تیم‌ها (مثل: The Beatles, Manchester United)\n",
    "\n",
    "🟧**creative-work** → آثار هنری یا رسانه‌ای (مثل: Harry Potter, Game of Thrones, Star Wars)\n",
    "\n",
    "\n",
    "این‌ها در واقع کلاس‌های موجودیت هستن که دیتاست تعریف کرده ⚡\n",
    "\n",
    " (یعنی هیچ موجودیتی نیست) می‌گیره  O یعنی هر توکنی که داخل متن هست، یا ⚡\n",
    "\n",
    " یا یکی از این برچسب‌ها\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "cells": [],
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "name": "python",
    "version": "3.10.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
