## sentiment-analysis-model
در این کد چهار مدل Encoder-Only داریم و یک دیتاست 20 کلاسه تحلیل احساسات

models : Estandard-Model , Model-1 , Model-2 , Model-3

#### Estandard-Model : 
یک مدل encoder-only با ترنسفورمر استاندارد

دلیل تعریف این مدل این است که یک مدل ترنسفورمر استاندارد به عنوان معیار داشته باشیم تا در هر گام عملکرد ۳ مدل را با مدل استاندارد مقایسه کنیم. ( در واقع یک جورایی همواره رفتارشون رو بررسی و کنترل میکنیم.)
#### Model-1 : 
یک مدل encoder-only  با یک ترنسفورمر هیبریدی ساخته شده با کانولوشن یک بعدی ( conv-attention )
#### Model-2 :
یک مدل encoder-only  با یک ترنسفورمر هیبریدی ساخته شده با شبکه عصبی بازگشتی gru ( مکانیزم توجه gru-attention)
#### Model-3 :
یک مدل encoder-only که از هر دو نوع مکانیزم توجه  conv-attention , gru-attention استفاده میکند. این مدل یک سریال از بلاک های انکودر استفاده شده در مدل های بالا است ( به شکل یکی در میون از انکودر های بالا استفاده میکند )

میخواهیم عملکرد هر 4 مدل را بر دیتاست بررسی کنیم

#### train-model-2 ( from-scratch )
مدل 2 بر دیتاست اموزش دیده است، ولی خب عملکرد جالبی نشان نداده است، احتمالا اصلی ترین دلیلش هم این است که تعداد ایپاک اموزشی خیلی کم است( مکانیزم توقف زودهنگام باعث توقف فرایند اموزش شد، تنظیماتش باید بهتر شود). این مورد در کد قابل مشاهده است.
دلیل دیگرش احتمالا مکانیزم gru-attention است.این مکانیزم همزمان دو کار انجام میدهد، هم حافظه کوتاه مدت دارد و هم مکانیزم توجه را پیاده میکند.
پس بیشتر با جزییات متن درگیر است و ممکن است این موضوع باعث شده باشد که مدل دیدی کلی به text ها برای طبقه بندی آنها به دست نیاورده باشد.( یا احتمالا به زمان خیلی بیشتری برای به دست اوردن این توانایی نیاز دارد)
به هر حال هنوز از اینکه دلیلش چه بوده که مدل ۲ روی دیتاست خوب عمل نکرده مطمئن نیستیم، برای کسب اطلاعات بیشتر از شیوه عملکرد مدل و تاثیر پارامتر ها رو آن ۲۳ بار روی subset های دیتاست اصلی مدل ها را train کرده ایم. نتایج در جدول زیر قابل مشاهده اند.


### Results
###### نتایج train های انجام شده روی دیتاست های بسیار کوچک در جدول زیر مشخص است. در هر شش Lab هر چهار مدل رو روی دیتاست خیلی کوچکی اموزش داده ایم. در هر اموزش پارامتر ها را تغییر داده ایم تا تاثیر پارامتر های مختلف را بر عملکرد مدل ببینیم. همچنین در این حین میتوان در هر Lab هر چهار مدل را نیز با هم مقایسه کرد.

| - | Lab-num | model | hidden-dim | num-layers | early-stopping (yes/no) | max-epochs | patience | trained-epochs |  min-delta | gradient-clip-val | train-data-size | val-data-size | test-data-size | f1-score | accuracy |
| - | --------| ----- | ---------- | ---------- | ----------------------- | ---------- | -------- | -------------  | ---------- | ---------------- | ---------------- | ------------- | -------------- | ------- | -------- |
| 1 | Lab-1 | estandard-model | 16 | 3 | yes | 6 | 3 | 4 | 0.00 | 1 | 3000 | 300 | 500 | 0.208 | 0.208 |
| 2 | Lab-1 | model-1 | 16 | 3 | yes | 6 | 3 | 4 | 0.00 | 1 | 3000 | 300 | 500 | 0.202 | 0.202 |
| 3 | Lab-1 | model-2 | 16 | 3 | yes | 6 | 3 | 4 | 0.00 | 1 | 3000 | 300 | 500 | 0.202 | 0.202 |
| 4 | Lab-1 | model-3 | 16 | 1 | yes | 6 | 3 | 4 | 0.00 | 1 | 3000| 300 | 500 | 0.202 | 0.202 |
| 5 | Lab-2 | estandard-model | 32 | 2 | yes | 6 | 3 | 4 |  0.00 | 1.0 | 3000 | 300 | 500 | 0.180 | 0.180 |
| 6 | Lab-2 | model-1 | 32 | 2 | yes | 6 | 3 | 6 |  0.00 | 1.0 | 3000 | 300 | 500 | 0.172 | 0.172 |
| 7 | Lab-2 | model-2 | 32 | 2 | yes | 6 | 3 | 4 |  0.00 | 1.0 | 3000 | 300 | 500 | 0.202 | 0.202 |
| 8 | Lab-2 | model-3 | 32 | 1 | yes | 6 | 3 | 4 |  0.00 | 1.0 | 3000 | 300 | 500 | 0.202 | 0.202 |
| 9 | Lab-3 | estandard-model | 16 | 4 | yes | 6 | 3 | 4 |  1e-3 | 1.0 | 3000 | 300 | 500 | 0.164 | 0.164 |
| 10 | Lab-3 | model-1 | 16 | 4 | yes | 6 | 3 | 4 |  1e-3 | 1.0 | 3000 | 300 | 500 | 0.202 | 0.202 |
| 11 | Lab-3 | model-2 | 16 | 4 | yes | 6 | 3 | 4 |  1e-3 | 1.0 | 3000 | 300 | 500 | 0.202 | 0.202 |
| 12 | Lab-3 | model-3 | 16 | 4 | yes | 6 | 3 | 4 |  1e-3 | 1.0 | 3000 | 300 | 500 | 0.202 | 0.202 |
| 13 | Lab-4 | est-model | 64 | 7 | yes | 6 | 3 | 4 |  1e-3 | 1.0 | 5000 | 650 | 800 | 0.207 | 0.207 |
| 14 | Lab-4 | model-1 | 64 | 10 | yes | 6 | 3 | 4 |  1e-3 | 1.0 | 5000 | 650 | 800 | 0.207 | 0.207 |
| 15 | Lab-4 | model-2 | 64 | 7 | yes | 6 | 3 | 4 |  1e-4 | 1.0 | 5000 | 650 | 800 | 0.207 | 0.207 |
| 16 | Lab-4 | model-3 | 64 | 5 | yes | 6 | 3 | 4 |  1e-2 | 1.0 | 5000 | 650 | 800 | 0.207 | 0.207 |
| 17 | Lab-5 | est-model | 8 | 15 | no | 20 | - | 20 |  - | 1.0 | 1000 | 100 | 200 | 0.230 | 0.230 |
| 18 | Lab-5 | model-1 | 8 | 15 | no | 6 | - | 6 |  - | 1.2 | 1000 | 100 | 200 | 0.230 | 0.230 |
| 19 | Lab-5 | model-2 | 8 | 20 | no | 8 | - | 8 |  - | 1.3 | 1000 | 100 | 200 | 0.206 | 0.206 |
| 20 | Lab-5 | model-3 | 8 | 15 | yes | 8 | 6 | 7 | 1e-3 | 1.5 | 1000 | 100 | 200 | 0.206 | 0.206 |
| 21 | Lab-6 | model-1 | 8 | 20 | no | 24 | - | 24 | - | 1.2 | 1000 | 100 | 200 | 0.230 | 0.230 |
| 22 | Lab-6 | model-2 | 4 | 10 | no | 25 | - | 25 | - | 1.3 | 1000 | 100 | 200 | 0.206 | 0.206 |
| 23 | Lab-6 | model-3 | 128 | 10 | no | 15 | - | 15 | - | 1.2 | 3000 | 500 | 600 | 0.200 | 0.200 |
